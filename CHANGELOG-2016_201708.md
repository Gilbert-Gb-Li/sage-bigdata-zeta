#17-01-06 更新
## feature
    1.优化数据库启动开始点逻辑，减少空转时间；
    2.ESWriter 增加nested 直增的逻辑；
#17-01-09 更新
## feature
    1.增加SFTP支持；
    2.ESWriter 增加nested 增加和更新的操作逻辑；
#17-01-13 更新
## bug fixed
    1.修复SFTP ，FTP 使用完连接后没有及时释放的bug；
## feature
    1.增加对kafka0.10的支持
#17-02-07 更新
## feature
    1.kafka支持保存读取位置及通配符
#17-02-08 更新
## feature
    1.增加KafkaDriver类
    2.支持连接认证授权过的kafka
#17-02-13更新
## feature
    1.DelimitStream merger line by line then split by delimit  …
    2.add KafkaDriver for kafka process
    3.kafka support for auth
## bug fixed
    1.stream close by reader bug fixed
#17-02-15更新
## feature
    1.net log reader with wrapper
#17-02-16更新
## bug fixed
    1.scala mapValue may cause stackoverflowerror
    2.filter bug Wrapper not support remove
    3.JDBC Stream bug func will make use table name
#17-02-17更新
## bug fixed
    1.net use akka udp and tcp for read
    2.jdbc forward only for read data
#17-02-20更新
## bug fixed
    1.bug fixes 修复数据源为kafka时，从数据库中恢复read position会出异常的问题
    2.bug for topic is only one
    3.bug for topic read lasted event and conputor error for topic position
    4.bug update parser not tag right
    5.bug delimit with \n \t \s replace to real and then
## feature
    1.读kafka支持用户自定义partition及相应offset的配置
    2.add support for kafka muti-topic read continue
#17-02-27更新
## bug fixed
    1.bug fixed for jdbc 不能识别BigDecimal 转double
#17-03-03更新
## feature
    1.kafka多种类型的topic配置增加文件续读的支持
#17-03-06更新
## feature
    1.kafka通配符配置topic支持topic、partition自动发现
## bug fixed
    1.bug fixed for flat method with null
#17-03-08更新
## bug fixed
    1.bug fixed ui ui-switch for string bool
    2.bug fixed for read  date from string
    3.bug fixed ftp sftp use lazy init for connect
## feature
    1.kafka数据源支持配置clientid
    2.db2 update driver to 4.22.25
#17-03-14更新
## bug fixed
    1.bug fixed when type array json for data format with array and sub type
## feature
    1.feature add when data not parse only transfer then out raw as real
#17-03-14更新
## bug fixed
    1.bug fixed flat reduce empty
#17-03-21更新
## bug fixed
    1.修复syslog不配置“来源主机及其数据编码”一项会导致数据源保存失败
    2.when tcp cache less then one line will truncate data as one
    3.file writer write line sp when write a empty file
    4.tcp used flow control,task cancel
## feature
    1.增加jdbc取值异常时输出异常位
    2.增加tcp、syslog数据截断问题的测试类
#17-03-25更新
## bug fixed
    1.修复kafka数据源必须设置groupId和clientId的问题
    2.修复数据存储为HDFS时权限校验不能正常设置的问题
    3.[ui]解析规则中的资产类型由span改为label
#17-03-30更新
## feature
    1.增加起止时间定时器
#17-05-27 更新
   version update to 1.0.1-Snapshot
   merge daemon with worker
   add ui in
#17-06-13 version 2.0.3
  
##bug fixed 
  1.  当文件数据源,正在监听数据文件时,删除文件,导致数据源关闭
      解决方案,当处理监听文件时,遇到文件不存在的错误时忽略
      影响的数据源包括,本地文件,hdfs,sftp,ftp等文件相关的
  2.  file stream  stream closed   exception
  3.  \#38  数据存储为"数据转发"时，报空指针异常
  4.  update preinstall.sh: add installation for netflow

  5.  \#32 界面停止worker时 有长时间的卡顿
      add master save worker status when it`s not running
  6.  can not stop netflow socket
  7.  preinstll.sh can not start daemon(1)
  8.  读取本地文件时,当文件超多时会OOM
  9.  读取多个文件是,已经读取完成的没有设置完成标记
  10. kafka 设置编码无法保存
  11. can not automatic update datasource when update writer

## FEATURE
 1.  更新管理员手册
 2.  add snmp mibble depends
 3.  update sage-bigdata-etl-Installation&deployment.md
 4.  add sage-bigdata-etl-design.md
 5.  add sage-bigdata-etl-manual.md
 6.  add sage-bigdata-etl-summary.md
 7.  add Server enable check on start worker
 8.  数据源是文件时,记录位置信息时,附带数据源ID
 9.  增强-同一个数据源-不管有多少文件(channal) 只使用一组输出
 10. add encoding for jdbc datasource
 11. MERGE DAEMON WITH WORKER
 
 #2017-08-02 version 2.5.0
##bug fixed
  193  kafka 作为数据源,当有多个topic时只读取一个
  195  数据存储使用HDFS时，运行数据源会导致worker重启
  183  修复解析规则修改时，数据过滤规则中，字段再解析子规则未显示问题
  189  数据过滤规则对于嵌套对象不起作用
  175  已被解析文件添加新数据，但新加的第一行解析失败
        采集器页面，当采集器状态为停止时，同时显示删除按钮。
        修改 索引的input 长度 为  4份
        数据源和数据存储添加kafaka 提示信息
        修改数据源类型为HDFS的错误字符
        数据源输入框的解释的长度超过输入框的长度时会导致无法看全
        kafka地址增加提示
  179  数据流运行时，未对数据存储字段列表的值进行校验      
  171  修改本地文件存储时，父级目录不存在，导致数据通道停止出现问题
  102  解析规则中的数据过滤（数据再解析）预览结果错误
  185  安装脚本需用能用方法支持未来更多插件的安装部署，比如 Excel，Hbase 等
  53   正则匹配sftp支持
  26
        1.如果将hbase作为reader，在数据源页面如果数据库类型选择hbase，右侧的"*库或实例名"是多余的。
        2.如果将hbase作为writer，可以把"主键列"隐藏。
  162  Windows下安装worker,使用plugin安装kafka插件，失败
 
##feature 
  29   flink 支持yarn模式debug
  29   实时SQL分析
  26   支持Hbase,读取,输出。
  
 #2017-08-07 version 2.5.1

##bug fixed
  213  在数据源里使用正则表达式来匹配目录下所有csv文件失败
  193  kafka作为数据源，数据丢失严重
  214  配置文件中 worker.id 保持默认会导致 worker.conf 文件被重置
  158  用同一份解析规则的json文件上传作为模板， 只会有一个最新的解析规则被创建
  137  数据源添加后分页信息更新不及时
  187  数据存储页面，数据输出格式标签项针对不同存储类型显示混乱
  190  下拉菜单默认添加第一个选中值
  
  208  增加@timestamp关键属性说明
  169  修改组件安装脚本
  
  212  使用数据库类型的数据源的时候无法使用Number类型字段作为索引列版本信息
  196  利用kafka采集性能数据的数据通道无法正常关闭
  199  本地文件数据源（JSON Codec）OutOfMemoryError
  184  数据源使用sftp,ftp 不可用
##enhancement
  211  重构部分代码从worker模块到core模块
  210  调整默认的数据传输序列化方式,使用kryo 来提高传输速度
  22   增加AIX系统中master停止脚本
       支持AIX系统中安装启动master、plugin
       修改setting.env中安装路径
##feature
  201  提交给客户的文档打包进安装包
  
# 2017-08-10 version 2.5.1.1  
 ##bug fixed   
   153  解析规则缺失
   158  上传同一份解析规则新增和更新问题
   164  Windows下安装worker，生成的日志文件logs路径错误，且无pids目录生成
   197  上传已有的kafka类型的json文件作为数据存储，修改配置中的kafka地址信息，运行数据源发现已经修改的信息并未修改彻底
   215  本地csv到kafka一段时间运行后出错

# 2017-08-15 version 2.5.2

## enhancement 
   226 sage-bigdata-etl 安装包瘦身,
      1. master,worker,auth,daemon 放到同一个安装包下;
      2. 调整打包脚本 支持放到同一个包下;
      3. 修改部分配置文件的依赖,更多的使用懒加载
## bug fixed
   258 UI上对“数据源->网络”页面上对“绑定的地址”的解释不清楚
   215 本地csv/excel到kafka一段时间运行后出错或者不读文件
   253 上传解析规则，点击上传，无响应
   260 sage-bigdata-etl worker 长时间运行，日志无正常内容,TCP 连接关闭有问题
   228 数据存储参考字段名称改为非必填项
   233 修复本地文件数据存储bug，添加本地文件 usability checker
   245 后台运行stop-daemon.bat,kill的是worker的进程，daemon进程仍然存在
        停止时，循环获取pid错误
   252 运行start.bat脚本安装启动worker成功,运行数据通道,失败
        该问题是由于替换worker.conf文件中的workerid后，导致conf文件错乱引起的
        修改workerid替换方式：使用脚本获取服务器hostname替换workerid
        修改范围：bat、bash、ksh三类脚本
    242 未安装插件提示，增加了不需要checker的几个插件的验证，包括excel，winevt，snmp，netflow等
## feature
   186 新增知识库相关接口文档 
   75  知识库相关接口,router和store
       ui for knowledge
 #2017-08-18 version 2.5.2.1
 
 ##bug fixed 
   288 创建数据源时，非必填项“参考字段名称“ 不设置，数据源无法创建
          writer default type es5
 
   248 数据存储选择“本地文件”，“文件路径”里显示多余字符
   271 preinstall.sh 安装插件失败, 
 
   270 运行kafka至es数据通道失败
         由于知识库模块修改了配置项,没有同步更新配置文件导致
   252 运行start.bat脚本安装启动worker成功,运行数据通道,失败
     
        1. 安装包中增加conf.template配置说明模板
        2. 修改该conf配置文件时，去掉中文注释信息，防止中文乱码问题
   253 上传解析规则，点击上传，无响应
 ##feature 
     186 知识库相关接口调整
 ##doc 
     186 用户手册、接口文档知识库相关补充
 ##enhancement
     修改auth windows脚本中的conf配置文件名称

#2017-08-22 version 2.5.2.2
   
   ## bug fixed 

    229 当"采集器已关闭,或者不存在"时，无法删除相关的数据通道
    
    243 当数据源来源是已经格式化好的数据时，`添加原始数据`没有效果
    233 修改错误提示信息不友好
    264 修改存储异常时，数据通道停止太慢
    268 daemon拉起worker的代码改动，现在所有模块在一个包，脚本名称改变。
    246 上传解析规则报出错误，但解析规则可以存储
    261 254 未安装插件提示 网络不通的提示
    247 上传数据源出错，错误信息有问题
    231 未安装插件提示
    251 在已经运行过的数据通道上点击重新读取，只读出一条数据
    239 新建数据源，选定文件类型为excel时，excel表头信息栏建议改为非必选项
    
 
 #2017-08-23 version 2.5.3
 
 ##bug fixed
    274  kafka的topic被某一数据通道读取后，其他数据通道无法再读取
    调整 数据源`数据转发`名称,更新为`数据订阅`
    调整 数据存储`数据转发`名称,更新为`数据发布`
    254 验证网络的checker，配置文件更新
        配置checker沒有配置的提示更新。并且在配置文件增加網絡的默認checker配置
    252 运行start.bat脚本安装启动worker成功,运行数据通道,失败
    272  CSV 文件，解析规则中样例预览字段总数错误
    

 ##enhancement
 
    273 增加lexer(flink) 相关的插件安装检查,调整相关的检查代码实现
    修改 application.conf.template配置信息
    275 增加上传文件的验证功能
    添加 自动完成及语法高亮到`脚本解析` `脚本过滤` 等页面
    删除 一些编译时的warn
##feature
    194  分析规则需要支持子规则,条件子规则需要实现的功能
         页面支持SQL语法高亮和关键字自动完成
         后端调整解析和分析的接口,实现接口分离
    
#2017-08-28 version 2.5.3.1   
   ## enhancement  
       #94 知识库页面脚本相关的支持语法高亮和自动完成
        excel  use iterator replace get
        286 `分隔符` 解析规则 UI调整
        ignore version set when publish

  ## bug fixed 
      插件安装代码使用isInstall() 导致很多规则 解析install 字段(jackson 自动解析的问题)
# 2017-08-29 version 2.5.3.2
   ##bug fixed 
          291 数据源列表页面资产类型不显示
          275 增加上传文件的验证功能
          276 修复Derby.log的路径问题
          289 windows下所有start-*.bat脚本启动失败
                  去掉logback-*中的注释，影响bat脚本运行
          159 Windows下安装worker,UI界面点击启动采集器，无响应
               修改bat关闭脚本
               修改daemon默认端口为19095
               修改daemon调用bat脚本命令结构
   ## enhancement 
          #288 增加CSV文件的直接支持
               添加对文件夹路径监听的时间等待,只需要暂停一下即可
          #186 知识库相关调整
#2017-08-30 version 2.5.3.3
   ##bug fixed
      292 启动含分析规则的数据通道会将work停掉
      295 Windows下，往已经解析的文件中追加数据，Position值未实时更新，导致读取到的数据条数有问题
  
      267 后台停止daemon,worker后，前台采集器页面列表为空
           修改master、worker启动脚本，替换logs输出绝对路径
           修改worker pom.xml文件，清楚组件引用配置
  
      159 Windows下安装worker,UI界面点击启动采集器，无响应
       
      186 知识库微调整
  
      197  去掉多余的after字母。
  
      294 数据通道本地csv到本地文件，数据解析出错
      251 在已经运行过的数据通道上点击重新读取，只读出一条数据
      238 运行的数据源为文本目录时，使用vim查看目录下某文件，导致日志报错
          增加相关的FAQ说明
      297 解析规则添加字段再解析后无法保存
      296 Windows下运行start-worker.bat自动退出，worker无法启动

  ##feature
      221 数据输出预处理接口需要实现的功能 接口方法
  ##enhancement 
      增加相关的配置对于超时,等情况
#2017-09-01 version 2.5.3.4
 ##bug fixed
   195 数据存储使用HDFS时，运行数据源会导致worker重启
    数据输出是`条件输出`时,无法选择其他`数据输出`
    修改js错误：双引号改为单引号
    190 sage-bigdata-etl的UI页面里很多的下拉菜单没有显示默认值，但实际上执行时是有默认值的
    239 新建数据源，选定文件类型为excel时，excel表头信息栏建议改为非必选项
    293 创建好的数据源的资产类型为空
    292 启动含分析规则的数据通道会将work停掉
 ##enhancement
    分组数据通道页面
    es2  es5 可以同时使用
   186 知识库：数据库为数据源加载到知识库调整
