[TOC]

sage-bigdata-etl 用户操作手册


**编写目的**

用户操作手册编写目的是明确本软件的功能、软件的作用、功能的操作，帮助用户理解及操作本软件。

**读者对象 **

系统管理员，运维人员、普通用户。

**修订信息 **

**修改记录**

**文档版本**V1.0 (2017-06-05)

[[[[[[]{#_Toc449098525 .anchor}]{#_Toc461973311 .anchor}]{#_Toc11552
.anchor}]{#_Toc16172 .anchor}]{#_Toc10227 .anchor}]{#_Toc479768905
.anchor}目录

目录 3

1\. 引言 6

1.1. 引言 6

1.2. 术语和定义 6

1.3. 运行环境 7

2\. 平台概述 7

2.1. 功能组件 7

2.2. 系统架构图 8

3\. 操作说明 9

3.1. 首页 10

3.2. 采集器 10

3.3. 数据存储 11

3.3.1. Elasticsearch 12

3.3.2. RabbitMQ 13

3.3.3. Kafka 14

3.3.4. SYSLOG 15

3.3.5. 网络 15

3.3.6. 数据库 16

3.3.7. 本地文件 17

3.3.8. HDFS 17

3.3.9. 数据转发 18

3.3.10条件输出 18

3.4. 解析规则 18

3.4.1. 字段说明 19

3.4.2. 解析类型 20

3.4.2.1. 不解析 20

3.4.2.2. CEF 20

3.4.2.3. 分隔符 21

3.4.3.4. 键值对 21

3.4.3.5. XML 22

3.4.3.6. JSON 23

3.4.3.7. 正则 24

3.4.3.8 传输 24

3.4.3 数据过滤 25

3.4.3.1. 添加字段 26

3.4.3.2. 删除字段 28

3.4.3.3. 字段重命名 28

3.4.3.4. 合并字段 29

3.4.3.5. 字段裁剪 30

3.4.3.6. 数据重定向 31

3.4.3.7. 匹配字段头 32

3.4.3.8. 匹配字段尾 33

3.4.3.9. 正则匹配 34

3.4.3.10. 包含 35

3.4.3.11. 字段再解析 35

3.4.3.12. 脚本解析 36

3.4.3.13. 脚本过滤 39

3.5.数据源 41

3.5.1. 字段说明 41

3.5.2. 源类型 42

3.5.2.1. 本地文件或目录 43

3.5.2.2. 网络 43

3.5.2.3. 数据库 45

3.5.2.4. FTP 46

3.5.2.5. SFTP 47

3.5.2.6. HDFS 48

3.5.2.7. KAFKA 49

3.5.2.8. RabbitMQ 50

3.5.2.9. ELASTICSEARCH 50

3.6.定时器 51

1.  引言
    ====

    1.   引言
        -----


sage-bigdata-etl是公司分析了多个项目需求，结合市面上众多的数据采集、收集系统的使用，发现有众多问题，不能适应新的需求的背景下，自主开发的一款支持更广泛,性能更优的数据采集与展示的软件。sage-bigdata-etl是一个分布式，可复用的高效数据采集录入系统，它提供从文本文件，网络日志，HDFS大数据平台，等读取数据，支持正则，*JSON*，XML，分隔符等多种数据格式的解析，录入到elasticsearch或者其他类的大数据分布式存储系统。

 术语和定义
-----------

-   ETL：是英文 Extract-Transform-Load
    > 的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

-   数据源：

-   解析规则：

-   数据存储：

-   OS：操作系统（OperatingSystem)

    1.   运行环境
        ---------

为了保证机器可以正常的使用本系统，请检查正在使用的机器是否符合最低配置的要求，建议采用推荐配置。

  -------------- ---------------------- ----------------------------
  项目           最低配置               推荐配置

  操作系统       CentOS 5               CentOS 6

  浏览器客户端   Internet Explorer9.0   Google chrome浏览器
                                        
                                        Internet Explorer9.0/10/11
                                        
                                        Firefox浏览器
  -------------- ---------------------- ----------------------------

1.  平台概述
    ========

    1.   功能组件
        ---------

<!-- -->

1.  采集器

2.  数据存储

3.  解析器

4.  数据源

5.  定时器

6.  资产

    1.   系统架构图
        -----------

![](media/image3.png){width="7.097222222222222in"
height="7.813888888888889in"}

1.  操作说明
    ========

    1.   首页
        -----

sage-bigdata-etl整体的页面设计使用标准的左右布局，左侧为导航栏，右侧为内容区或展示区，首页默认显示系统数据源，包括数据源名称，数据源状态，当前登录用户等信息。

![](media/image4.png){width="7.095138888888889in"
height="1.3159722222222223in"}

 采集器
-------

显示采集器ID，主机ip，主机端口，运行状态等信息。可通过操作栏按钮“启动/停止”采集器。

![](media/image5.png){width="7.095138888888889in"
height="1.3868055555555556in"}

当采集器停止时，可点击“删除”按钮删除采集器信息（采集器如有使用则不可删除）。

![](media/image6.png){width="7.095138888888889in"
height="1.3756944444444446in"}

3.3. 数据存储
-------------

列表显示数据存储名称，存储类型

![](media/image7.png){width="7.086111111111111in"
height="1.5305555555555554in"}

操作：点击“+”，页面如下图所示：

![](media/image8.png){width="7.089583333333334in"
height="2.2284722222222224in"}

名称：数据存储名称

类型：可选以下几种

![](media/image9.png){width="4.061805555555556in"
height="2.1041666666666665in"}

### 3.3.1. Elasticsearch

选择数据存储类型为es时，可参照下图配置：

![](media/image10.png){width="7.095138888888889in"
height="3.573611111111111in"}

必填字段说明（“\*”标注）：

1.  .集群名称：es集群名称

2.  .集群地址：此处可填写1\~n个节点的ip、prot

3.  索引：数据存储的索引。一般配置为动态的索引名称（参考图中填写的“logs\_\$，也可写死，如直接填写字符串“logs”），每天产生一个，“\$”为占位符，可根据参考字段动态生成。如参考字段为时间（参考图中“索引字段参考”选项），则把时间格式化成字符串（参考图中“时间字段名称”和“时间格式化方式”字段）填写到“\$”处。

4.  索引类型：es索引类型

5.  分片数：创建索引时的shard数量

6.  副本数：创建索引时的[]{#OLE_LINK1 .anchor}replication数量

### 3.3.2. RabbitMQ

选择数据存储类型为RabbitMQ时，可参照下图配置：![](media/image11.png){width="7.095833333333333in"
height="2.4520833333333334in"}

必填字段说明（“\*”标注）：

1.  主机地址：ip地址

2.  端口：prot

3.  队列名称：QUEUE\_NAME 

### 3.3.3. Kafka

选择数据存储类型为Kafka时，可参照下图配置：

![](media/image12.png){width="7.100694444444445in"
height="1.8909722222222223in"}

必填字段说明（“\*”标注）：

1.  TOPIC：kafka中数据存储的主题

2.  KAFKA地址：可填写1\~n个kafka节点的ip:port，多个时中间用“,”隔开

### 3.3.4. SYSLOG

选择数据存储类型为SYSLOG时，可参照下图配置：

![](media/image13.png){width="7.095833333333333in"
height="1.3534722222222222in"}

必填字段说明（“\*”标注）：

1.  发送到的地址：syslog发送到的主机ip

2.  发送到的端口：syslog发送到的主机端口

3.  通信协议：udp/tcp可选

### 3.3.5. 网络

同上

### 3.3.6. 数据库

选择数据存储类型为数据库时，可参照下图配置：

![](media/image14.png){width="7.097222222222222in"
height="1.8805555555555555in"}

必填字段说明（“\*”标注）：

1）数据库类型：可选以下类型

![](media/image15.png){width="4.061805555555556in" height="1.6875in"}

2.  库和实例名：数据库名称

3.  数据库地址：数据库所在主机ip

4.  端口：数据库端口

5.  用户名

6.  密码

7.  数据表

8.  主键列：主键列名，如“id”

### 3.3.7. 本地文件

选择数据存储类型为本地文件时，可参照下图配置：

![](media/image16.png){width="7.0993055555555555in"
height="1.3381944444444445in"}

必填字段说明（“\*”标注）：

1.  文件路径：此处可填写固定的文件路径，也可填写带通配符的文件路径。如图所示，表示采集“/opt/gendata”目录下所有以“.txt”结尾文件的数据。

### 3.3.8. HDFS

选择数据存储类型为HDFS时，可参照下图配置：

![](media/image17.png){width="7.097222222222222in"
height="1.8979166666666667in"}

必填字段说明（“\*”标注）：

1.  HOST：HDFS部署主机ip

2.  PORT：HDFS端口

3.  文件路径：此处可填写固定的文件路径，也可填写带通配符的文件路径。如图所示，表示采集“/user/bigdata/test/kafka-hdfs”目录下所有以“metricsbeat-”开头并以“.data”结尾文件的数据。同时此路径也支持“\$”占位符动态采集数据，具体请参见3.3.1.1中“索引”字段的配置方式

### 3.3.9. 数据转发

这种数据存储方式是把数据直接传输给sage-bigdata-etl
worker采集器，由采集器接收写入的数据。

![](media/image18.png){width="7.092361111111111in"
height="0.8270833333333333in"}

### 3.3.10条件输出

3.4. 解析规则
-------------

### 3.4.1. 字段说明

![](media/image19.png){width="7.093055555555556in"
height="2.2083333333333335in"}

在解析规则管理中点击添加按钮，添加页面主要有一下几个字段：

1）解析规则名称

2）样例日志：当有格式一致的日志时，可以复制粘贴一条日志到这里，程序会自动按照下面配置的解析规则来进行分析，点击结果预览就可看见按照解析规则解析后的样子。

3）日志类型：选择解析规则所依赖的日志类型

4）解析规则：解析日志的规则（具体见1.2解析类型）

5）数据过滤：对解析的日志进行二次修改（具体见1.3数据过滤规则）

6）数据结果预览：对解析的结果进行预览，注意：此功能只有在输入样例日志时才能有预览的效果；只有点击预览，才能出现保存的按钮。

#### 3.4.2. 解析类型

可选以下类型：

![](media/image20.png){width="4.061805555555556in" height="1.6875in"}

在解析规则管理中的解析类型分别有一下几种：注意符号中\\s表示空格，\\n表示换行，\\t表示tab

#### 3.4.2.1. 不解析

不对日志进行解析，直接传输，传输进去的日志在raw字段中，如下图所示

![](media/image21.png){width="7.268055555555556in"
height="2.7930555555555556in"}

#### 3.4.2.2. CEF

解析CEF格式的日志

#### 3.4.2.3. 分隔符

以分隔符分开每条日志，字段列表中可以设置日志的字段名以及字段多少，粘贴样例日志，填写好分隔符，点击字段列表的加号，显示出各个字段，可以对其进行重命名，点击预览即可看见解析后的样子如下图所示：

![](media/image22.png){width="7.268055555555556in" height="4.73125in"}

#### 3.4.3.4. 键值对

填写字段分隔符：分割字段的符号；键值分割符：分割字段名称和字段值得符号；如下图所示，日志的字段分割符为“,”,键值符为“=”

![](media/image23.png){width="7.268055555555556in"
height="3.917361111111111in"}

#### 3.4.3.5. XML

适用于解析带有xml格式的日志，如日志样例为：

&lt;recipename&gt;Ice Cream Sundae&lt;/recipename&gt;

&lt;itemdescription&gt;chocolate syrup or chocolate
fudge&lt;/itemdescription&gt;

&lt;preptime&gt;5 minutes&lt;/preptime&gt;

&lt;quantity&gt;3&lt;/quantity&gt;

配置规则为下图：

![](media/image24.png){width="7.268055555555556in"
height="3.6618055555555555in"}

#### 3.4.3.6. JSON

适用于解析带有json格式的日志

#### 3.4.3.7. 正则

适用于复杂的其他形式无法解析的日志，在下面的GROK表达式中写入正则表达式进行解析，格式为：

%{规则名:字段名}日志分割符号，如下面的例子中，date就为第一个字段，字段值为2015-09-09，date和time之间间隔的是空格。常用于网络吐出来的数据。

![](media/image25.png){width="7.268055555555556in"
height="4.8381944444444445in"}

#### 3.4.3.8 传输

不对日志进行解析，直接传输，相对于不解析类型，原始日志不会在raw字段中出现

### 3.4.3 数据过滤

在解析规则管理中另可配置多种格式的日志，就是数据过滤，以下是数据过滤的多种方法：

![](media/image26.png){width="1.65625in" height="2.7291666666666665in"}

注意：这里的字段都为小写!

#### 3.4.3.1. 添加字段

在原有日志字段的基础上添加新的字段：

点击下面的加号，出现两个输入框，前面的输入要添加的字段名，后面写要添加的字段的值，

值分两种：一种是固定的，直接在里面写值就好，如图1，添加完的c字段的值为3

另一种变量，可以取已有字段的值，取值格式为%{想取的值的字段名}，前面和后面也可以直接写固定的值，

如图2，添加完的c的字段的值为1\_4

![](media/image27.png){width="7.268055555555556in"
height="4.354861111111111in"}

图1

![](media/image28.png){width="7.268055555555556in"
height="3.964583333333333in"}

图2

#### 3.4.3.2. 删除字段

删除想删除的字段，在下面输入字段名称，如下图即为删掉a字段

![](media/image29.png){width="7.107638888888889in"
height="4.225694444444445in"}

#### 3.4.3.3. 字段重命名

更改字段的名字，前面输入原字段名，后面输入新的字段名，如下图将原来的date字段重命名为@timestamp字段

![](media/image30.png){width="6.870138888888889in"
height="4.477777777777778in"}

#### 3.4.3.4. 合并字段

合并多个字段为一个，点击加号，前面输入合并后的字段名，后面输入要合并的字段名，如下图所示即为合并date和time字段为一个@timestamp字段

![](media/image31.png){width="7.268055555555556in"
height="4.554166666666666in"}

#### 3.4.3.5. 字段裁剪

对字段的值进行剪裁，前面输入要剪裁的字段名，后面输入开始剪裁的位置，和剪裁的长度，如下图所示，即为剪裁掉protect\_id字段值里的前3个值，入进es里的值为244

![](media/image32.png){width="7.268055555555556in"
height="4.366666666666666in"}

#### 3.4.3.6. 数据重定向

对字段进行多重设置，当某个字段值为多少时，对该字段进行再次过滤，如下图即是当字段client\_ip的值为192.168.3.21时，添加字段date；常用于多个数据吐一个端口时，可以对host字段做数据重定向。

![](media/image33.png){width="7.164583333333334in"
height="4.669444444444444in"}

#### 3.4.3.7. 匹配字段头

与数据重定向类似，当字段的值为多少时，对字段进行再次过滤，不过可以从前开始匹配，如字段Protocol有HTTP，TCP等，如下的设置就为当Protocol字段的值从头开始解析，为H时，对字段进行再次解析，将Client\_IP字段重命名为src

![](media/image34.png){width="7.268055555555556in"
height="2.567361111111111in"}

#### 3.4.3.8. 匹配字段尾

与匹配字段头类似，不过是从字段值得后面开始匹配，如字段email字段的值有gary@xxx.com,henry@xxx.cn，如下设置即为当email字段值为xxx.com时，对数据进行再次解析,删除字段act

![](media/image35.png){width="7.268055555555556in"
height="2.7041666666666666in"}

#### 3.4.3.9. 正则匹配

使用正则匹配个别字段，输入要匹配的字段，匹配的该字段值的规则；以下如图即为当第一个字段为四个数字时，添加字段date，取值field1

![](media/image36.png){width="7.268055555555556in"
height="3.303472222222222in"}

#### 3.4.3.10. 包含

与字段重定向类似，字段重定向是全部匹配，包含是包含输入值就可以再做过滤。

如下图是src字段中的值包含202时，就会删除src字段

![](media/image37.png){width="7.268055555555556in"
height="2.952777777777778in"}

#### 3.4.3.11. 字段再解析

对某个字段进行再次解析，且解析规则为其他类型。

如下图中即是对info字段进行再次解析，解析规则为dd

![](media/image38.png){width="7.268055555555556in"
height="3.9430555555555555in"}

#### 3.4.3.12. 脚本解析

对某种数据通过简单的javascript脚本进行添加、删除、修改字段

示例1：添加字段，将解析完的字段添加一个“d”字段，如下图所示

![](media/image39.png){width="7.101388888888889in"
height="4.7965277777777775in"}

图1

示例2：添加字段的同同时删除字段，将解析完的字段添加一个“d”字段，删除一个“a”字段，如下图所示

![](media/image40.png){width="7.100694444444445in"
height="4.679861111111111in"}

图二

图二与图一对比，可看出“a”字段已经被删除。

#### 3.4.3.13. 脚本过滤

对某种数据通过简单的javascript脚本进行过滤，对过滤到的数据进行以下操作：

![](media/image41.png){width="2.895138888888889in"
height="1.8958333333333333in"}

示例：

![](media/image42.png){width="7.090277777777778in"
height="5.304861111111111in"}

对包含有a，b，c三个字段的数据进行过滤，当a的值为1时，删除字段b。

3.5.数据源
----------

### 3.5.1. 字段说明 {#字段说明-1 .ListParagraph}

1）数据源名称

2）采集器：系统会自动获取到采集器，选择要使用的那台

3）日志类型：日志所属的类型

4）资产：可选可不选，选择后，所添加进来的日志会自动补上所属资产的相关字段，方便以后做事件告警识别

5）解析规则：系统根据所选的日志类型而显示关联的解析规则

6）源类型：数据源写入方式（具体见3.5.3源类型）

7）解码器：

单行：适用于一行一条的日志；

多行：适用于有多行为一条的日志，正则填写正则规则，如果从头开始匹配就为true，反之为false；例如下面这条日志：

2016-05-03 19:44:27.83 Server Microsoft SQL Server 2008 (RTM) -
10.0.1600.22 (Intel X86)

Jul 9 2008 14:43:34

Copyright (c) 1988-2008 Microsoft Corporation

Enterprise Evaluation Edition on Windows NT 6.1 &lt;X86&gt; (Build 7601:
Service Pack 1) (VM)

2016-05-03 19:44:27.83 Server (c) 2005 Microsoft Corporation.

2016-05-03 19:44:27.83 Server All rights reserved.

2016-05-03 19:44:27.83 Server Server process ID is 1828.

正则填写：/d{4}；是否从头开始匹配选择true；意为从第一行开头开始匹配遇见4个数字的就为一条日志；

XML格式：解析跨行的xml文件时在这里选择，如果单行的话可以在解析规则里面配置；（未实现）

JSON格式：解析跨行的json文件时在这里选择，如果单行的话可以在解析规则里面配置；（测试未通过）

8）超时时间和轮询时间
只当读取数据时，发现没有数据等待多久去再次读取否则提示超时；到一次读取超时后下次要再次读取数据使用的等待时间-轮询时间；

9）数据存储；对于当前的数据源，数据输出到什么位置（多选-每个数据输出一份数据）

### 3.5.2. 源类型 {#源类型 .ListParagraph}

#### 3.5.2.1. 本地文件或目录 {#本地文件或目录 .ListParagraph}

![](media/image43.png){width="7.096527777777778in"
height="3.196527777777778in"}

适用：日志以文件的形式存在在采集器那台机器上

字段说明：

1）文件路径：存放文件的位置，绝对路径,可指定到具体文件

2）编码：文件的格式编码有:自识别，utf-8，gbk，unicode，使用默认自识别即可

4）文件类型：txt,winevt

5）文件续读：”是”是上传读取到的地方读，” 否”是从文件开头开始读

6）跳过开始行数：从最开始的第一行开始算起，跳过几行写几行，跳过的不对其进行读取

#### 3.5.2.2. 网络 {#网络-1 .ListParagraph}

![](media/image44.png){width="7.1in" height="3.098611111111111in"}

适用：日志以网络形式传输到采集器上

字段说明：

1）绑定地址：默认0.0.0.0，采集器的IP

2）内容类型：其中网络包含以下几种

![](media/image45.png){width="4.061805555555556in"
height="1.2708333333333333in"}

3）通信协议：udp，tcp

4）绑定的端口：发到采集器上的端口

5）编码

6）数据缓存：默认1000，如果数据量大的话建议改成5000-10000

7）监听主机及其数据编码：可以监听多个主机，主机填写主机号，编码填写日志的编码格式（目前这里的编码格式不能用，传的是上面的编码）

#### 3.5.2.3. 数据库 {#数据库-1 .ListParagraph}

![](media/image46.png){width="7.092361111111111in" height="3.78125in"}

适用：日志为数据库中数据表的时候

字段说明：

1）数据库类型：选择录入的数据库类型

2）数据库地址：数据库所在的IP

3）端口：数据库的端口（一般默认即可）

4）数据库或实例名：要解析的数据库名或实例名

5）数据表名或sql：要解析的数据表名或select语句，没测过函数

6）索引列名称：当做索引的列名，建议是日期或id的字段列

7）索引开始的位置：索引列读取的数据其实位置，注意不包含本身，建议向前写一位

8）索引步长：注意时间的步长以秒为单位

9）用户名：连接数据库的用户名

10）密码：连接数据库的密码

#### 3.5.2.4. FTP {#ftp .ListParagraph}

![](media/image47.png){width="7.100694444444445in"
height="3.6243055555555554in"}

适用：解析文件服务器上面的日志，与本地文件目录的数据源类似

字段说明：

1）HOST：ftp的ip

2）port：ftp的端口，默认为21

3）用户名：登录ftp的用户名，匿名登录时可以不填

4）密码：登录ftp的密码，匿名登录时可以不填

#### 3.5.2.5. SFTP {#sftp .ListParagraph}

![](media/image48.png){width="7.093055555555556in"
height="3.6972222222222224in"}

适用：解析文件服务器上面的日志，与本地文件目录的数据源类似

字段说明：

1）HOST：sftp的ip

2）port：sftp的端口，默认为22

3）用户名：登录ftp的用户名，匿名登录时可以不填

4）密码：登录ftp的密码，匿名登录时可以不填

#### 3.5.2.6. HDFS {#hdfs-1 .ListParagraph}

![](media/image49.png){width="7.095833333333333in" height="3.5875in"}

适用：读取hadoop文件系统中的文件

字段说明：

1）HOST：hadoop系统的IP

2）PORT：hadoop系统的端口

3）authorization：是否需要验证，如果hadoop系统中安装了安全协议，建议选择是，否则就否

4）authorization：安全的具体协议

5）文件路径：hadoop系统里面的文件路径

#### 3.5.2.7. KAFKA {#kafka-1 .ListParagraph}

![](media/image50.png){width="7.094444444444444in" height="3.375in"}

适用：读取kafka系统中的数据

字段说明：

1）数据缓存

2）topic：要读取的主题名字

3）编码

4）增加HostPorts：主机：IP地址；端口：该主机kafka系统里对应的端口

#### 3.5.2.8. RabbitMQ {#rabbitmq-1 .ListParagraph}

![](media/image51.png){width="7.097222222222222in"
height="3.2472222222222222in"}

适用：读取RabbitMQ系统中的数据

字段说明：

1）数据缓存

2）虚拟主机：Rabbit中的虚拟主机地址

2）队列名称：要读取的队列名字

3）编码

4）主机：IP地址；

5）端口：该主机RabbitMQ的RPC端口

#### 3.5.2.9. ELASTICSEARCH {#elasticsearch-1 .ListParagraph}

![](media/image52.png){width="7.097222222222222in"
height="3.046527777777778in"}

适用：读取ELASTICSEARCH的数据

字段说明：

1）数据缓存

2）索引：要读取的索引名字

3）TYPE

4）主机：IP地址；

5）端口：该主机ELASTICSEARCH对应的RPC端口

3.6.定时器
----------

通过定时器，可控制数据源的启动、停止、重新启动等动作。

![](media/image53.png){width="7.088888888888889in"
height="2.0388888888888888in"}

字段说明：

1.  名称：定时器名称

2.  数据源：选择要控制的数据源

3.  操作：可选如下操作

    ![](media/image54.png){width="4.061805555555556in"
    height="0.6458333333333334in"}

4.  类型：可选如下类型

    ![](media/image55.png){width="4.061805555555556in"
    height="0.4375in"}

<!-- -->

a.  固定时间间隔：

    ![](media/image56.png){width="7.100694444444445in"
    height="0.3680555555555556in"}

    开始时间：设置开始时间，目前为时间字符串（yyyy-MM-dd HH:mm:ss）

    时间间隔：设置定时器执行频率，单位为毫秒

b.  日历时间间隔：

    ![](media/image57.png){width="7.094444444444444in"
    height="0.33958333333333335in"}

    Crontab表达式：标准Crontab格式

    5）启用

# 特殊使用说明
 1.  作为数据`传输` `转发` 通道 
   >当使用解析规则为`传输` 或者 `不解析` 时,切没有任何其他的规则添加
   > 这个时候执行传输的动作,数据原样输出,不受 `数据存储` 的数据`输出格式` 影响

3.7. 知识库管理
-------------
#### 3.7.1.字段说明

![](media/image58.png){width="7.095833333333333in"
                          height="1.3534722222222222in"}
    
在知识库管理页面中点击添加按钮，添加页面主要有以下几个必填字段（“\*”标注）：

1）知识库名称：知识库的名字

2）资产类型：选择资产类型

3）采集器：选择采集器

4）数据源：选择知识库的数据源

5）解析规则：系统根据所选的日志类型而显示关联的解析规则

#### 3.7.2.基本使用

可参照下图进行配置：

![](media/image59.png){width="7.095833333333333in"
                          height="1.3534722222222222in"}
    
点击保存即可。  

按钮从左至右，依次是修改/查看知识库配置、删除、加载、复制知识库和下载配置数据操作。

#### 3.7.3.配合解析规则使用

知识库单条数据举例：code = 00020, note = note_20

![](media/image60.png){width="7.095833333333333in"
    height="1.3534722222222222in"}

点击预览，知识库补充相关字段，如下所示。

![](media/image61.png){width="7.095833333333333in"
    height="1.3534722222222222in"}

   