注：超出以下范围的功能不保证能工作

功能范围：
一、安装： 
     1.只支持一键安装
     2.linux支持master(1个) + worker（主要验证redhat7.2）
	   
二、数据（解析）通道：
     1.kafka，本地文件（文本，excel，csv），网络（syslog），Mysql，FTP，SFTP和HDFS作为数据源  
     2.使用知识库导入数据(omdb)（仅支持数据源为mysql）
     3.解析规则中支持知识库补充进行相关信息的补充
     4.ES5，Kafka，网络（syslog），HDFS，Mysql和本地文件（json格式）作为数据存储

三、数据（分析）通道：
     1.本地文件（json格式），Kafka，HDFS，ES5，网络（syslog）作为数据存储
     2.分析类型支持SQL，时间序列预测和日志归并
	 
四、数据建模通道：
     1.HDFS，ES5作为数据源
	 2.分析类型支持SQL，时间序列预测和日志归并
	 3.本地文件（json格式），Kafka，HDFS，ES5，网络（syslog）作为数据存储

五、解码器：
     1. 单行
	 2. 多行
	 	 
	 
已知问题：
#744  关联知识库时，未将关联的知识库字段名转化成小写后再关联到数据中                                  
#753  配置master多活，无法形成集群，日志报错
#755  系统形成master集群后，页面没有管理master的地方
#756  形成master集群后，运行知识库，没有日志生成 
#757  master集群形成后，master中采集器worker显示不全  
#762  多worker配置下，依次运行多个数据通道成功，页面显示部分通道运行状态一直处于停止态
#763  多worker配置，依次运行10个数据通道，其中部分通道的数据源文件读取时间过长，存储长时间无submit
#764  数据存储为es5时，修改es5中字段类型，重新运行该数据通道，页面没有报错信息提示
#765  初始自动安装关闭auth后，重新设置master.conf中打开auth，重启master，输入ip:port，auth验证没有生效
#767  多worker配置，依次运行10个数据通道，运行一段时间后，其中有3个数据通道的worker不再有日志生成
#770  Cli-collector启动时对sage-bigdata-etl.sh 内java启动需要的内存变量大小， 没有检查
#773  Worker重启时应该给相关的数据通道发信号，保证数据通道的状态正确  
#777  数据存储为es5，数据通道运行后部分数据没有正常存储，记录到了error中(ES报错queue capacity = 50)
#778  执行升级脚本，打印信息有歧义，建议修改
#779  待升级版本的auth为开启状态，升级时配置auth为关闭状态，升级成功后auth仍然为开启状态
#720 查看长时间运行的数据通道，采集进度图页面没有曲线图和数据显示
#719 当“时间类型”为日志字段时间时，分析规则中指定字段类型和关联的解析规则中对应字段类型不一致时，未进行校验
#717 解析通道kafka到ES5 性能问题（主要为读取和解析） 
#716 查看已运行数据通道的采集进度图，页面图例显示重复
#715 数据通道停止后，读取的数据没有全部处理完成存入数据存储
#714 上传解析规则，解析规则中存在知识库补充的过滤规则，如果依赖的知识库不存在，解析规则保存成功。当运行依赖该解析规则的数据通道时，没有校验提示
#713 运行存储至网络类型的数据通道，当网络不稳定时，存储得到的结果会丢失数据
#711 当数据源类型是本地文件时，文件路径配置一个不正确的正则，数据通道状态一直是“ 初始状态 ”，并且不能停止数据通道 
#589 运行ES5作为数据源的数据通道失败 
#695 hdfs/本地文件数据源，当指定的文件不存在时，运行数据通道，页面无提示信息 
#388 mysql作为数据存储时，未校验指定的"主键列"
#642 mysql作为数据存储，当解析规中配置了字段@timestamp时,导致写数据异常
#606 运行Mysql作为数据存储的数据通道，存储的结果错误
#704 数据源为ftp时，运行数据通道无法读取文件名为汉字的文件 
#620 Kafka作为数据源时，指定的topic不存在，运行数据通道无任何错误提示 
#694 数据源解码器为“多行”时，给运行的数据通道添加数据，数据存储结果的第一条数据部分缺失 
#697 数据源解码器为“分隔符”时，往读取过的数据源文件中追加数据，解析得到的结果错误 
#706 数据源解码器为“XML”时，往已经读取过的文件中追加数据，会偶发性读取条数为0 
#676 运行存储至ES5的数据通道/数据建模，当ES5环境异常时，写数据异常，未有超时时间的限制
#702 存储至网络(TCP)时，当网络不稳定时,写入失败,切无法恢复 
#699 运行存储至mysql的分析通道/数据建模，均运行失败
#356 分析规则中指定字段为解析规则中没有的字段，运行数据通道，未有任何提示信息 
#669 运行分析通道（日志归并） ，采集进度中输出永远为0
#665 分析完成的分析规则通道采集进度页面，曲线图和总数没有显示分析和存储的数据 
#637 查看数据通道进度图，选择较大时间范围查询，移动光标趋势图浮层只显示一个时间点数据
#281 数据通道（本地excel文件到kafka）运行一段时间后，往本地目录下新增多个文件，读取到部分文件的数据条数为0                                
#265 doc目录下文档以及sage-bigdata-etl-2.5.2-SNAPSHOT目录下README，RELEASENOTES都未更新


   




Bug Fixed:
#  2018-01-12 version 2.6.1.5 
## bug fixed 
    766 运行分析通道和数据建模失败
    772 数据源为多行时，匹配行数较大，日志有报错，数据通道不在读取之后的数据
    771 数据通道中对应的采集器不存在时，删除数据通道失败并报错
    761 删除数据通道“解析规则json”，新建数据通道重新命名为“解析规则json”点击保存，页面报错

#  2018-01-09 version 2.6.1.4 
##  bug fixed 
    758 启动master和worker后运行数据通道，master和worker均无日志生成

#  2018-01-08 version 2.6.1.3
## bug fixed 
  	752 默认出厂配置 gated 有问题 调整到10s
  	742 运行存储至es的数据通道，es异常又恢复之后，存储得到的数据条数有多余
	
#  2017-12-12 version 2.6.1.2
##bug fixed
    700 修改 AkkaOutputFormat 构造参数，规避类型匹配错误...
    701 数据源ftp/sftp，文件类型为excel有表头，存储数据结果默认之前数据源页面填写过的表头信息
    671 分析规则中指定源数据文件中不存在的字段时，运行存储至es5的数据建模，得到的结果中缺失该字段
    698 分析规则预览时报出错误“请安装flink相关模块！”，而实际上flink相关插件都已经安装
    696 数据源解码器为“json”时，给运行的通道添加数据，数据存储结果的多出部分数据
    680 未安装flink插件时，新建数据建模页面点击“测试连接”，页面提示信息不准确

#  2017-12-07 version 2.6.0.18
## bug fixed 
    692 omdb知识库运行后，状态为未知

#  2017-12-06 version 2.6.0.17
## bug fixed 
    688 数据源为“网络”类型，通讯协议为tcp时，运行数据通道，得到的数据存储中存在空行
    684 未安装mysql插件，运行存储至mysql的数据通道，页面提示信息不准确
    668 分析规则的SQL中使用时间窗口时，预览失败
    681 Windows环境下，运行分析通道，缺少对streaming插件的校验
    680 未安装flink插件时，新建数据建模页面点击“测试连接”，页面提示信息不准确
    683 数据建模列表不显示数据
    682 修改cli-collector安装文档
    679 修改Modeling任务的状态控制：在FlinkJob提交完成后，设置Modeling任务状态为运行

#  2017-11-30 version 2.6.0.16
## bug fixed
    677 Windows环境上面，安装modeling插件后，运行数据建模，仍然提示modeling插件未安装
    548 添加对于存储异常的建模任务的停止操作(错误更新修复...)
    546 延长建模任务前段请求超时时间
    641 时间序列使用文档更新
    668  添加测试用例
    634 分析规则部分的使用文档，需要更新
    666 当数据通道为分析通道时，曲线图图标和统计列表显示“分析”字样
    661  对项目增加认证
    655 启停分析通道时，worker日志有异常报错信息
    632 修复Metrics信息查询时间与曲线图横坐标显示不一致的问题
    594 修复使用文档，添加FAQ说明

#  2017-11-30 version 2.6.0.15 
## bug fixed
    659 分析规则添加指定字段时，选定关联出来的字段，页面报错
    662 修复float转double的异常
    626 数据源为ftp，文件路径带“-”的情况，运行数据通道不能读取到数据
    658 数据存储为ES5时，运行数据通道失败，worker假死
    657 添加Modeling hdfs 数据源jar包依赖
    667 新建分析类型为“日志归并”的分析规则，成功，但是页面报错

#  2017-11-28 version 2.6.0.14 hot fixed
##bug fixed 
    655 解析规则中嵌套字段,重命名失效
    652  修复删除分析规则,提示正在被数据通道使用.实际上二者之间没有任何关系.[勿更改,之前是ok的]
    579 登录页面，填写用户名或密码后又删除，两个输入框间距发生变化
    646 ES数据源添加端口提示
    639 修改分析通道模板，更新相关脚本
    552 修复删除被数据建模绑定的数据源/分析规则/数据存储未做校验的问题.
    648 新建数据通道后无法删除
    594 添加解码器相关说明

#  2017-11-27 version 2.6.0.13 hot fixed
##bug fixed
    643 一键安装脚本增加 netstat 命令校验
    修改时间序列结果的格式
    修改时间序列ARIMA预测不成功
    修改时间序列预测结果时间显示不正确的问题
    设置所给数据量必须大于一个周期的数据
    修改预测结果时间差一个粒度的bug
 
#  2017-11-27 version 2.6.0.12
 ## bug fixed
    556 校验上传数据建模时的字段.
    643 一键安装脚本增加netstat命令校验
    628 更新使用文档
    282 添加Metrics说明
    644 消除grok 解析中对'_字段名' 的hack 特殊处理
    637 优化数据抽取算法
    530 删除被分析通道绑定的数据通道，未进行校验，直接删除成功
    639 修改分析通道模板，更新相关脚本
    625 运行数据源为HDFS的的数据通道失败， 报hdfs插件未安装，但实际上hdfs插件已安装
    630 字段再解析不能对含有"."符号的属性名称再解析
    631 分析规则中，选择“日志字段时间”，当使用不解析的解析规则时，无法选择“时间字段”
    638 dev分支中只支持linux和window系统安装包编译，测试环境中需要支持aix和hpux的安装包编译
    634 分析规则部分的使用文档，需要更新
    467 sftp\ftp 正则路径不能读取数据问题
    633 分析规则中“最大延迟时间”的提示信息显示不全
    628 Modeling使用的ES数据源未对时间字段进行解析，导致FlinkJob执行时发生类型转换的错误
    624 抽取出 构建FlinkJob失败的原因，并展示出来。
    618 登陆后如果auth server出现问题，页面无法被刷新，并且没有提示!
    582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
    627 运行分析通道成功，点击“点击查看flink任务” 失败
    495 ftp、sftp指定文件不能读取的问题
    623 复制分析规则，选择解析规则后，添加字段属性不可用
    622 HDFS作为数据源时，默认的端口8020不能使用，应改为9000
    540 校验成功时隐藏错误提示
    621 Modeling 表单验证添加红色框提示；
    617 Flink测试连接添加表单验证
    603 频繁多次起停数据通道/分析通道/离线建模/知识库操作，会导致偶发性服务器 [0.0.0.0] 在 [5] s内没有响应报错(或是发生异常：...)
    589 运行ES5作为数据源的数据通道失败
    453 数据存储为es2(es5)，数据通道运行中，重启es，数据通道不能自动恢复正常，一直处于写数据异常状态
    613 存储为 ES5时，接收数据会产生文档数为0的 错误索引
    616 运行一个以ES5为数据存储的数据通道，ES5集群状态从不可用到可用，导致入库ES5的数据解析失败
    576 多个数据通道/建模，数据存储为相同索引和索引类型的ES5，启停部分数据通道/建模会影响其他的数据通道/建模存储失败

#  2017-11-17 version 2.6.0.11 
## bug fixed
    612  后台连接失败问题，导致数据通道运行失败 减去hbse对netty包的依赖,避免冲突
    582  一键安装配置setting.conf文件未提供portal认证时的配置及说明
    588 运行分析通道失败，页面详细报错信息丢失
    607 当“采集器已关闭,或者不存在”时，运行数据通道，提示信息不合理
    605  网络不好，导致“采集器已关闭，或者不存在“
    536 未对flink状态进行校验导致分析通道运行失败，前台未有任何报错提示信息
    568 细化错误信息提示；  完善异常捕获。
    484 去除空行结果
    530 删除被分析通道绑定的分析规则/数据通道，未进行校验，直接删除成功
    609 修复Modeling插件检验导致Worker异常停止
    306 分析规则中: (1)“指定字段”的类型为空 可以保存 (2)"解析规则“为空可以保存
    569 删除被分析规则绑定的解析规则时，未进行校验，直接删除成功
    601 去掉跳转连接；
    600 去掉bug标示。
    475 在无jre和jdk的Linux系统中一键自动安装sage-bigdata-etl ，当setting.env可修改项端口修改为已被占用的端口，安装过程中无报错或者提示
    531 更改默认端口避免与 OMDB，Portal 及 CCI 冲突
    286 gulp 编译问题; `分隔符` 解析规则 UI调整
    595 文档《CLI-Collector使用手册-v11》中知识库对应的解析规则，建议使用文档中进行详细说明

# 2017-11-17 version 2.6.0.10 hotfix
## bug fixed 
    526 数据源hdfs，文件类型为excel有表头，存储数据结果默认之前数据源页面填写过的表头信息
    582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
    595 文档《CLI-Collector使用手册-v11》中知识库对应的解析规则，建议使用文档中进行详细说明

# 2017-11-15 version 2.6.0.9 hotfix
## bug fixed
  567 删除Modeling下载配置中的JobId
  591 修复Modeling 中状态检查 bug，修改 Modeling 任务启停逻辑
  596 统一数据库所有表中，创建时间字段为：CREATE_TIME,修改时间字段为：LAST_TIME, 部分表增加IS_SAMPLE字段
  440  数据源类型为本地文件或目录，文件路径为本地目录，运行通道失败
  569 删除被分析规则绑定的解析规则时，未进行校验，直接删除成功
  562 setting.env中配置了mysql的安装，一键安装成功后，运行数据存储为mysql的数据通道失败，提示jdbc插件未安装
  543 上传知识库模板时，采集器为空，但是保存成功
  534 运行分析通道，分析结果中select解析通道中的字段c@receive_time值错误
  508 建议分析规则模板的SQL语句中不要使用"*"
  571 数据建模修复数据源不存在，前端无错误：添加运行时错误捕获并显示与前端
  563 fixed 解析规则数据过滤选择知识库补充，下拉框选项出现未运行的知识库

# 2017-11-14 version 2.6.0.8 hotfix
## bug fixed
    356 分析规则中指定字段为解析规则中没有的字段，运行数据通道，未有任何提示信息
    508 建议分析规则模板的SQL语句中不要使用"*"
    582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
    586 复杂解析规则等编辑内容导致保存操作403错误
    570 建模添加数据源、分析插件、数据存储校验；
    584 修改 FlinkAPI 返回值类型错误；
    585 运行数据源为csv的数据通道失败

# 2017-11-14 version 2.6.0.7 hotfix
## bug fixed
  581 一键安装时，配置文件setting.env添加安装的插件ftp，sftp，hdfs，excel，导致安装失败
  583 修复Flink提交缺少analyzer jar 包的问题
  577 添加测试连接功能；
  551 拆分列表
  517 复制的分析规则修改添加字段时，无法自动关联到解析规则中的字段名
  135 "解析规则"缺失，但预览时未报任何错误
  530 删除被分析通道绑定的分析规则/数据通道，未进行校验，直接删除成功

# 2017-11-13 version 2.6.0.6 
## bug fixed 
    304 采集器后台进程存在，页面采集器状态已关闭或者不存在，采集器不可用
          1. 修改worker连接Master的策略 client ,每次重建;
          2. 修改 页面停止worker的逻辑,不使用Await,并检查 daemon 返回的状态;
    281 数据通道（本地excel文件到kafka）运行一段时间后，往本地目录下新增多个文件，读取到部分文件的数据条数为0
    529 修复页面图标显示异常;
    562 setting.env中配置了mysql的安装，一键安装成功后，运行数据存储为mysql的数据通道失败，提示jdbc插件未安装
    560 自动安装sage-bigdata-etl，在初始化数据库时有删表失败error提示，建议文档中添加说明
    558 ES2/ES5数据存储页面集群名称缺少必填项标志
    467 数据源为ftp，sftp时，文件路径为正则匹配，不能匹配读取到对应文件
    540 对时间段查询校验，添加错误提示
    518 数据源为kafka，解析过滤规则为知识库补充，存储为es5。运行数据通道，数据无法解析并存储。多次起停操作，提示失败，采集器被关闭
    519 数据源为kafka，给已完成解析的kafka中添加数据，再次启动数据通道后数据读取数据错误
    476 已经运行成功的知识库，再次点击运行，状态不会变
    378 选择数据源为sftp，"文件路径"指定到目录导致运行数据通道失败
    520 CLI-Collector使用手册验证
    529 发行版中应该携带版本信息 
    484 修复建模遇到空行自动补填问题
    493 数据源为本地文件或类型，文件类型为csv，填写表头信息，运行数据通道得到的数据默认源文件第一行数据为表头信息
    440 数据源类型为本地文件或目录，文件路径为本地目录，运行通道失败。
    298 Kafka读取超时，导致只有部分数据存入ES2，但UI上无任何错误提示
    370 日志缺少kafka写入，和读取的详细信息,例如写入多少条数据，读取了多少条数据
    561 增加文档说明默认开箱即用的模板 