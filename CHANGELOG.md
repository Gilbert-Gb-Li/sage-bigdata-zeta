# 2018-10-16  version 3.0.1.2
## bug fixed 
    1.  #ZETA-21 start shell check memory error!
    2.  #ZETA-19 数据存储,选择分隔符格式,期望可以使用特殊的格式,例如:\t,\s,\n
    3.  integer short long not recognize '-1' '-2'
    4.  elasticsearch not recognize none script upsert error
    5.  #ZETA-3 woker生成日志定时删除功能不起作用 by log package update
    6.  #ZETA-15 zeta解析规则数据源为目录时，不能进行数据预览报错
            root cause:watcher service not close when close monitor
    7.  https://issues.apache.org/jira/browse/DERBY-6737 
    8.  preview matedata not match data cols
    9.  preview when datasource show nothing for raw data
    10. that dev env grok-partten not work 
## enhancement 
    1.  #ZETA-20 自定义UDF 添加long类型时间戳转换为时间类型
    2.  add protobuff lexer conf to template
    3.  add elasticsearch 6.x script running for page setting
    4.  upgrade flink version to 1.6.1
    5.  knowledge load user caffeine cache
    6.  after merged , not do  remove with the fields
    7.  json parser error,then add raw data with error info
    8.  ReplaceProcessor usr regex
    9.  add field multi
    10. add field additive
    11. add field value replace
    12. add data extends from sub array
    
    
## feature
    1.  add unzip filter
    2.  add zip filter
    3.  add protobuff lexer
    4.  add avro lexer
    5.  percentRank function for cal percent rate
    6.  add hive support for ui-config
    


#  2018-06-11 version 3.0.0.11
##bug fixed 
	1002 flink任务关闭时会导致 worker重连 master
	998 运行数据分析类型的数据建模，分析规则为分词（ansj）,运行失败
	996 修改报错信息,提示不支持的数据源类型
	995 分析规则是“分类：支持向量机“的数据建模生成模型失败，查看flink状态失败
	994 隐藏了未实现的功能
	992 任务调度类型为“数据通道”的任务列表下拉框通道选项显示没有规律
	991 任务调度中绑定的通道能被删除，且页面没有不能删除的提示信息
	990 查询列表排序
	988 解析规则预览时，修改字段类型，再次点击预览后修改的字段类型复原
	987 解析规则预览导致worker进程停止
	986 运行数据分析类型的数据建模，分析规则为日志归并（未绑定模型），生成结果错误
	985 分析通道第一次运行成功，第二次运行失败（并未提交flink job的情况）后，通道状态绑定的flink job 还是第一次运行时生成的
	983 使用SQL关键字在UI上会有提示
	983  修复了数据通道状态可能显示错误的BUG
	
	984 新建“聚合：日志归并”类型的分析规则，保存后刷新，再次打开，部分配置项内容为空
	982 复制分析通道后，状态相关的flink任务也被复制
	981 分析通道绑定分析规则为分词（ansj），运行失败
	980 回归的数据集划分
	979 数据源为es5的建模通道生产模型失败，flink运行失败
	977 对参与Join的每一个数据通道分别设置时间类型，窗口的时间类型根据Join成员的时间类型自动选择。
	966 修改了图标
	962 worker.out文件中存储了所有的日志信息，和worker-时间戳.log文件内容重复，耗用过多存储
	961 运行kafka至es5的分析通道，运行一段时间后失败，页面采集器显示已关闭或不存在
	945 预处理：文本向量化类型的分析规则，向量化方式为SIM-HAH时，生成模型时写数据失败
	938  增加了分析规则和数据存储的重名提示
	924 运行数据建模失败后，点击bug图标，显示出的错误信息越出了黑框范围，不便观看错误信息
	916  优化了Worker启停流程
	891 flink(AkkaOutputFormat)与Worker连接超时，导致分析数据丢失
	825 sftp类型数据源，预览测试成功，worker日志有报错
	808 分析规则测试预览失败
	802 "数据源转表"、“通道组合”支持预览
## feature
	#740 svm模型参数修改
    #971 lda 降维算法实现
    957 实现算法的图像展示与可视化参数调整
    971 lda 降维算法实现
    980 回归的数据集划分

## doc 
	支持向量机和时间序列文档更新
 	线性回归使用文档-v5
## enhancement 
	954 重构分析的模型名称

#  2018-05-28 version 3.0.0.10
## feature 
    971 lda降维算法flink 实现 
        回归的数据集划分
    955 增加逻辑回归分类算法实现   
    897 实现流式处理的每个算子对模型的动态加载
    818 时间序列模型输出修改，目的是画出模型的残差图，判断模型的好坏 
## bug fixed 
    977 修复 在“通道组合”中选择“数据到达时间”，运行使用该组合的分析通道时报错
    969 解析规则中数据过滤的名称只能显示一个字
    967 更改了图标和文字
    966 修改了图标样式
    965 任务调度页面日志信息描述“第1执行START操作......”不通顺缺少“次”字，应为“第1次.....”
    964 任务调度：知识库 启动后一直打印重复日志信息，无法区分是否在下一个时间点执行任务
    962 worker.out文件中存储了所有的日志信息，和worker-时间戳.log文件内容重复，耗用过多存储
    963 任务调度模块的日志信息默认只显示十条信息，建议分页显示多条
    961 运行kafka至es5的分析通道，运行一段时间后失败，页面采集器显示已关闭或不存在
    960 解析规则添加过滤规则“删除”后预览结果显示被部分空白
    959 解析规则添加过滤规则后，不满足条件的数据对应字段被删除后预览结果显示错乱
    957 实现算法的图像展示与可视化参数调整
    956 数据源绑定的采集器被删除后，1 预览测试无响应 2 保存成功
    952 修复 源类型为“组合通道”时，通道一、二的属性必须相同（联动)
    951 数据通道页面es5存储写入异常后，一段时间后采集器停止运行，查看worker进程挂掉
    949 修复Metrics计量翻倍问题
    947 修复 运行数据建模时报空指针错误
    946 文本向量化类型的分析规则，向量化方式为TF/IDF时，生成模型时数组越界
    944 预处理：分词类型的分析规则，分词器选择“ANSJ”时，保存失败
    942 预处理：分词类型的分析规则，分词器选择“ANSJ”时，保存失败
    938 新建解析规则命名与之前重复，保存后报错，页面没有明确提示命名重复
    936 获取知识库id修改
    930 解析规则重命名后预览显示重命名前的字段
    926  “预处理：文本向量化”分析规则，向量化方式为SIM-HASH时,选择向量化长度，保存后再打开该分析规则，向量化长度栏为空
    924 运行数据建模失败后，点击bug图标，显示出的错误信息越出了黑框范围，不便观看错误信息
    916  ui页面无法停止采集器，点击停止页面报错：“未发现采集器 的守护进程”
    809 通道列表按创建时间排序（倒序）
    716 修复重复图例
    695 HDFS数据源，指定文件不存在时，运行数据通道会有提示，数据通道可以正常监听
    674 分析通道添加Metrics计量
    669 修复分析通道采集进度Metrics为0的bug
## enhancement 
    954 重构分析的模型名称
    950 调整时间窗，时间模式的配置方式
    834 数据源类型为sql单通道时，“指定字段”名称没有自动完成功能
    实现流式处理的每个算子对模型的动态加载

#  2018-05-08 version 3.0.0.9 hot fixed
##bug fiexd
    942 农信）解析单个文件时，通道运行一段时间后，解析速率变慢，再运行一段时间，日志突然骤增，迅速耗尽存储空间
    939 运行sql类型数据建模，无结果生成
    932 数据建模通道无法删除，页面提示“不允许 [DELETE] 操作！” 问题详细描述
    934 预览大数据量的ES5数据源，没有预览结果显示，导致采集器停止运行
    924 运行数据建模失败后，点击bug图标，显示出的错误信息越出了黑框范围，不便观看错误信息
    920新建“预处理：PCA(降维)”类型的分析规则，保存失败
    915 数据建模的数据源数据量较大时，数据存储结果与数据源数据不一致
    909 联合分析的子通道是分析通道时，时间序列预测的分析通道运行后没有结果产生
    848 数据源字段较多时解析规则预览后页面显示效果不好（数据源预览显示效果不好）
    828 升级master未同步db数据到新版本目录下，导致删除最初安装的版本目录后，所有数据丢失
    740 SVM算法实时和离线二分类输入数据类型修改
    725 添加API接口说明
##enhancement 
    941 当通道启动,flink不能够连接到worker时,任务结束
    935 任务调度页面，详情中日志信息描述不直观，建议文字显示
    907 支持复杂结构对象的字段在分析规则中应用 flink json格式化 类型转换错误
    912 修改建模输出时的调用
    937 调整知识库信息查询的接口
##feature
    728 通道/数据建模/知识库单任务定时调度功能
##demo
  sage-bigdata-etl-tabs标签页组件，使用bootstrap标签页样式
    使用方式参考：views/demo/tab.html
 

#  2018-04-16 version 3.0.0.8 hot fixed
## bug fixed 
    928  预览结果,跟实际结果不一致 reset for pom
    922  ES 输出速度慢
    919 运行“预处理：分词”类型和“预处理：文本向量化”的分析通道，报插件未安装。而plugin目录下没有相应名称插件
## enhancement 
    907 支持复杂结构对象的字段在分析规则中应用
 

#  2018-04-16 version 3.0.0.7 fail
## bug fixed 
	908 mysql类型的数据源，当被指索引名含有特殊字符时，提示加上引号
	911 修复数据建模的flink任务偶发被取消
	910 worker使用脚步解析时,导致解析速度很慢
	906 页面部分输入框的说明展示不全
	905 [Bug]sql类型的分析规则中，无法使用table.@timestamp字段
	904 当只添加了样例数据,没有添加参考数据源时,无法添加过滤规则
	903日志归并类型分析规则,保存成功后,刷新页面再次打开,时间字段显示不全
	902 ES 对于类型转换错误
	901 修复多通道Join时，分析通道运行报错：Parallelism of an operator must be at least 1
	898 在《时间序列预测使用文档》中添加实时分析时使用联合分析对通道时间类型的要求
	894 修复 “聚合分析的子通道为联合分析时，数据建模运行失败”
	893 建模支持解析规则中的字段类型转换和数据过滤
	893 完善RuleProcessorFactory支持类型
	888 “多通道联合分析”时去掉“ProcessingTime”选项
	859 数据源类型为网络时，点击预览测试没有显示的数据源，提示数据源为空
	851 创建一个数据源，点击测试预览后，再新建一个数据，仍显示上一个数据源预览的结果
	817 给运行的数据通道（数据存储为es5）每60秒添加一次数据，运行一晚上后查看不再读写数据
	816 页面重启worker成功，master日志中有报错信息
	809 数据建模中的数据通道列表进行分组显示
	809 数据通道列表进行分组显示
	809 数据通道选择框按“名称”排序显示
	808 [Bug]分析规则测试预览失败
	777 数据存储为es5，数据通道运行后部分数据没有正常存储，记录到了error中(ES报错queue capacity = 50)
	742 运行存储至es2的数据通道，es2异常又恢复之后，存储得到的数据条数有多余
	728 通道/数据建模/知识库单任务定时调度功能
	725 添加接口API说明
	711 当数据源类型是本地文件时，文件路径配置一个不正确的正则，数据通道状态一直是“初始状态，并且不能停止数据通道
	704 FTP现可以读取中文文件名
	697 数据源解码器为“分隔符”时，往读取过的数据源文件中追加数据，解析得到的结果错误
	695 hdfs/本地文件数据源，当指定的文件不存在时，运行数据通道，页面无提示信息
#  2018-03-26 version 3.0.0.6
##bug fixed 
    818 时间序列实时分析输出修改，模型匹配代码修改
    896 ElasticseachInputFormat 在flink上使用时没有释放连接
    895 数据源为es5时，数据建模和解析通道使用的时间格式不一致
    881 分析规则为时间序列类型页面的“时间字段”没有必填项标识
    857 分析规则中，参考数据通道字段为非必选字段，但是一旦选择后无法不选
    871 添加 上传数据源“用作预览的采集器”、“数据通道”必要字段的验证
    881 分析规则为时间序列类型页面的“时间字段”没有必填项标识
    861 修复 “运行数据源类型为分析通道转数据表的分析通道，运行后无结果生成” 的问题
    889 数据源为es5时，端口输入框提示信息错误，现在端口统一为9300
    851 创建一个数据源，点击测试预览后，再新建一个数据，仍显示上一个数据源预览的结果
    870 修复逻辑判断错误
    887 数据源的“时间类型”由Event time改为Processing time时，分析通道运行失败
##feature 
    886 多源回归算法 迁移spark的实现到sage-bigdata-etl项目中
        aiteratively WeightedLeastSquares
        Vector merge has error
        迁移spark的实现到sage-bigdata-etl项目中
    831 文本切词 添加ansj实现
    740 SVM算法二分类建模参数和离线分析输出修改
##enhancement
    813 分析规则为sql类型时，分析通道未对绑定的数据通道是否已经转换为数据表进行校验


#  2018-03-19 version 3.0.0.5
## feature  
    873 新增多源回归算法
    826 实现tf/idf 文本向量化
    775 对于新版的多源的预览

## Enhancement
        813 分析规则为sql类型时，分析通道未对绑定的数据通道是否已经转换为数据表进行校验
        393 logagg去掉minhash
        854 分析规则,预处理规则页面调整
        826 文本向量化 SIM HASH  调优
## bug fixed 
        789 设置DataSet Parallelism默认值为1
        808 [Bug]分析规则测试预览失败
        870 修复“编辑”、“复制”时报错问题
        879 运行数据源为es5（大数据量）的数据通道，读取数据比实际数据源多
        818 时间序列算法离线和实时分析修改（HoltWinters模型）
        641 时间序列使用文档更新
        873 在流式向量标准化时多增加了一列
        884 构建dag出错
        843 [Bug]解析规则中选择“参考数据源”之后，不应该触发预览
        867 任务调度页面上传一个名称重复的任务，页面没有提示信息
        878 创建SQL和 LOGAGGS类型分析规则时，参考数据通道置空，保存。点击修改，参考数据通道下拉框显示为空
        877 重新启用 FlinkJob 检查机制
        873 es作为数据源建模超时
        876 运行知识库后，在知识库信息管理界面查询结果，再次运行该知识库，运行失败
        启动知识库后不断地连接daemon
        874  hdfs 作为建模使用时,不能同时启动多个
        862 数据存储是kafka类型的数据通道运行失败，页面报错
        803
        872 修复  数据建模使用 SQL进行 三张表（三个数据源）分析时报类型匹配错误
        863 任务调度Quartz表达式样例时间举例较特殊，无法区分时分秒月日的填写位置
        865 新建任务调度保存后不显示任务名称
        740 SVM算法修改
        855 删除数据建模绑定的“通道组合”和“通道转数据表”类型的数据源时，可以成功删除且没有
        832 运行一个数据源为hdfs的数据通道后，创建新的hdfs数据源不能正常预览，日志报错
        803 数据存储类型为数据库时，页面“字段及类型”表格显示问题
        840 解析规则页面"添加字段属性"按钮展示问题
        853 新建分析规则类型为“预处理”保存后页面不显示任何分析规则
        851 创建一个数据源，点击测试预览后，再新建一个数据，仍显示上一个数据源预览的结果


#  2018-03-05 version 3.0.0.4
## feature 
    826 实现tf/idf 文本向量化 添加输出到知识库/从知识库加载
    845 添加HMM算法实现
    831  文本切词
    SplitTokenizerProcesser.scala 切词API接口及实现类
    ModelingWordSegmentation 切词
    ModelingWordSegmentationTest 切词测试
## doc
    使用手册更新：数据建模添加“分析类别”说明
    修改使用文档：更新数据建模部分
    统一名称 “SQL单通道” -> “通道转数据表”；添加多通道说明文档
    时间序列算法文档更新
## bug fixed 
    848 数据源字段较多时解析规则预览后页面显示效果不好
    835 解析规则中，参考数据源字段为非必选字段，但是一旦选择后无法不选
    849 被数据建模绑定的数据通道可以被删除，且页面没有提示信息
    842 被数据源类型是“sql单通道”和“通道组合”绑定的数据通道可以删除，页面没有提示信息
    803 数据存储类型为数据库时，页面“字段及类型”表格显示问题
    846 修复运行分析通道时报序列化错误
    840 解析规则页面"添加字段属性"按钮展示问题
    841 删除正在使用的分析规则，页面提示信息样式，字体颜色与其他页面不一样
    836 数据源页面"数据预读”字段没有实际作用，去掉该显示
    837 kafka类型数据源预览返回的结果错误
    830 kafka作为数据源的数据通道，运行成功后重置，再次运行，读取不到数据
    697 数据源解码器为“分隔符”时，往读取过的数据源文件中追加数据，解析得到的结果错误
    822 新建分析规则页面，“参考数据通道”下拉框不显示任何数据通道
    817 给运行的数据通道（数据存储为es5）每60秒添加一次数据，运行一晚上后查看不再读写数据
    742 运行存储至es2的数据通道，es2异常又恢复之后，存储得到的数据条数有多余
    777 数据存储为es5，数据通道运行后部分数据没有正常存储，记录到了error中(ES报错queue capacity = 50)
    823 时间序列预测类型的分析规则，页面“时间字段”输入框展示问题
    774 数据源预览，类型为本地文件，本地文件不存在或错误路径时，点击预览后没有提示，后台日志不停的打印
    775 对于新版的多源的预览
    694 修复多行解码器 记录读取位置不准确
    817 给运行的数据通道（数据存储为es5）每60秒添加一次数据，运行一晚上后查看不再读写数据
    712 数据建模处于正在停止状态时显示停止按钮
## enhancement 
    847 添加构建DAG错误提示
        时间序列算法离线分析修改
    827 修改Metrics信息保留时间
        添加Metrics信息清理机制


#  2018-02-07 version 3.0.0.3 

 ## feature 
    818 时间序列建模 支持分组,多指标同时计算
    775 对于新版的多源的预览
    527 增加ntp 时间同步服务

## bug fixed
    807 [Bug]未安装hdfs插件导致hdfs类型数据源预览测试失败，页面未有任何提示信息
	819 修复 创建Metrics 索引报错
 	697 数据源解码器为“分隔符”时，往读取过的数据源文件中追加数据，解析得到的结果错误
 	806 去除Modeling 复制、下载时的FlinkID属性
 	811 取消“组合通道”添加字段时对解析规则的验证
 	814 数据源为ES的数据通道，运行成功后重置，再次运行，读取不到数据
 	805 数据通道从kafka读取数据写入es2, 数据读取完毕之后,停止数据通道再次运行,数据重复写入了一遍.
 	393 logaggs算法流式处理修复解析bug
 	642 mysql作为数据存储，当解析规中配置了字段@timestamp时,导致写数据异常
 	799 Channel校验已经完成，回滚Checker校验逻辑（去除Channel校验通过临时解决修改）
 	772 数据源为多行时，匹配行数较大，日志有报错，数据通道不在读取之后的数据(解决代码合并问题)
## enhancement 
	653 统一ES 的client调整接口直接读取数据
	710 Metrics 分表存储
	693 ES5作为数据存储时，如果索引为新建，建议在UI添加按钮来决定是否enable “_size” field
	776 多步骤分析组合成一个DAG任务
      		由树形 转换成 有向无环图
	799 多通道的插件校验
	759 升级flink到1.4
## doc	
	641 时间序列使用文档更新

#  2018-01-23 version 3.0.0.2  3.0 版本发布

##bug fixed
        784 修正错误配置文件
        783 重启master后，运行数据通道，通道运行状态一直显示停止状态
        606 运行Mysql作为数据存储的数据通道，存储的结果错误（数据库作为输出，表结构定义放到输出定义）
        642 mysql作为数据存储，当解析规中配置了字段@timestamp时,导致写数据异常
        663 数据存储-作为知识库
        765 初始自动安装关闭auth后，重新设置master.conf中打开auth，重启master，输入ip:port，auth验证没有生效（增加FAQ说明）
        782 SQL 过滤规则 无法使用
        709 修复停止采集器时数据通道测量数据丢失的问题
        578 登录页面不填写用户名或密码提示信息为：“请填写此字段”，建议为："用户名不能为空"和"密码不能为空"
        749 json 解析 当字段开头是换行时,解析错误
        748 读取数据后，解析规则为不解析，存储到hdfs或file时，输出的数据间隔有空行
##feature 
        653  统一ES的client api
        740  调整算法实现 使之可以在远端执行
        537 JDBC数据源和数据存储支持使用不同驱动连接数据库(Sybase支持)
        740 SVM算法实现
        728 通道/数据建模/知识库定时任务调度功能
                    取消/重启/启停功能.
                    其他的功能已在本地测试OK!
        651 flink升级后，pca的升级
        664 DBSCAN 聚类算法实现 页面修改
        524 [feature] 时间序列离线建模-知识库通路
        128 [analyzer] 需要针对多数据通道设计数据组合条件
        128 修改 多通道分析配置结构组织方式 为启动时组织。
        727 logaggs 修改成并发模型
        590 pca算法实现
        645 文本-向量化

##enhancement 
        768 优化代码结构 pom 文件依赖关系调整
        693 ES5作为数据存储时，如果索引为新建，建议在UI添加按钮来决定是否enable “_size” field
        468 关于文件类数据源:`续读字段` 数据源中的“文件续(重)读”策略
        770 Cli-collector启动时对sage-bigdata-etl.sh 内java启动需要的内存变量大小， 没有检查
        759 升级flink到1.4
        537 JDBC数据源和数据存储支持使用不同驱动连接数据库
        768 优化代码结构,减少reverse调用
         完善输出(syslog 协议的配置)
        462 知识库存入derby的内容在UI上无法操作
        751 调整开发环境下分析加载对于部分编译时无法使用的错误
        650 数据分析引用知识库作为数据模型
            修改启动脚本GC策略
##DOC
        ES2/ES5数据存储,文档缺少部分字段的介绍



#  2018-01-12 version 2.6.1.5 
## bug fixed 
    766 运行分析通道和数据建模失败
    772 数据源为多行时，匹配行数较大，日志有报错，数据通道不在读取之后的数据
    771 数据通道中对应的采集器不存在时，删除数据通道失败并报错
    761 删除数据通道“解析规则json”，新建数据通道重新命名为“解析规则json”点击保存，页面报错
## enhancement   
    769 增加升级脚本
    

#  2018-01-09 version 2.6.1.4 hot fixed
##  bug fixed 
    758 启动master和worker后运行数据通道，master和worker均无日志生成
#  2018-01-08 version 2.6.1.3
## bug fixed 
   	753 配置master多活，无法形成集群，日志报错
  	752 默认出厂配置 gated 有问题 调整到10s
  	744 关联知识库时，未将关联的知识库字段名转化成小写后再关联到数据中
  	743 参数maxHistory未生效，默认值为10，但生成的日志数超过10
  	742 运行存储至es2的数据通道，es2异常又恢复之后，存储得到的数据条数有多余


#  2017-12-28 version 2.6.1.2 hot fix
##bug fixed 
    741 数据源为本地文件目录，运行数据通道后状态为：写数据异常
#  2017-12-27 version 2.6.1.1
##bug fixed 
    280 数据通道（kafka到es2）运行一个小时后，已经采集的总量不会变化，日志里也再无ES相关内容
    672 解析通道 kafka到ES5， 运行一段时间后，ES5出错，导致通道出错，但ES5恢复后通道无法恢复
    453 数据存储为es2(es5)，数据通道运行中，重启es，数据通道不能自动恢复正常，一直处于写数据异常状态
    366 数据过滤规则中“default”处理使用“删除” 后，导致使用正则，包含等过滤规则不生效
    722 查看分析规则模板，当“时间类型”为日志字段时间时，“最大延迟时间”默认值是0
    630 字段再解析不能对含有"."符号的属性名称再解析
    707 Script 解析或者过滤会导致后台异常,增加相关的异常处理
    495 数据源为ftp，sftp时，给已解析过的文件中添加数据，新增数据不被读取 在2.6的更新
##doc 
    更新cli-web安装使用手册
    《CLI-Collector使用手册-v15.6.docx》使用手册验证，请修改更新手册
##enhancement
    703 更新DB2-diag解析模板，解决日期后时区解析问题
    705 更新Oracle-listener和Oracle-alert解析模板

#  2017-12-12 version 2.6.0.19
##bug fixed
    700 修改 AkkaOutputFormat 构造参数，规避类型匹配错误...
    702 运行数据源为excel类型的数据通道，存储至网络时，部分数据写入失败
    701 数据源ftp/sftp，文件类型为excel有表头，存储数据结果默认之前数据源页面填写过的表头信息
    672 解析通道 kafka到ES5， 运行一段时间后，ES5出错，导致通道出错，但ES5恢复后通道无法恢复
    671 分析规则中指定源数据文件中不存在的字段时，运行存储至es5的数据建模，得到的结果中缺失该字段
    698 分析规则预览时报出错误“请安装flink相关模块！”，而实际上flink相关插件都已经安装
    696 数据源解码器为“json”时，给运行的通道添加数据，数据存储结果的多出部分数据
    660 数据源为mysql的数据通道，运行成功后重置，再次运行，读取不到数据(目前的设计，可能需要重新讨论)
    680 未安装flink插件时，新建数据建模页面点击“测试连接”，页面提示信息不准确
##feature
    393 LogAggs 算法
   
##enhancement
    703 更新DB2-diag解析模板，解决日期后时区解析问题
## DOC
    690 《CLI-Collector使用手册-v15.5.docx》分析规则中，时间序列预测说明较简单

#  2017-12-07 version 2.6.0.18
## bug fixed 
    692 omdb知识库运行后，状态为未知
##enhancement     
    674 添加FlinkJob Metrics 获取API
#  2017-12-06 version 2.6.0.17
## bug fixed 
    688 数据源为“网络”类型，通讯协议为tcp时，运行数据通道，得到的数据存储中存在空行
    684 未安装mysql插件，运行存储至mysql的数据通道，页面提示信息不准确
    668 分析规则的SQL中使用时间窗口时，预览失败
    671 分析规则中指定源数据文件中不存在的字段时，运行存储至es5的数据建模，得到的结果中缺失该字段
    681 Windows环境下，运行分析通道，缺少对streaming插件的校验
    680 未安装flink插件时，新建数据建模页面点击“测试连接”，页面提示信息不准确
    683 数据建模列表不显示数据
    682 修改cli-collector安装文档
    679 修改Modeling任务的状态控制：在FlinkJob提交完成后，设置Modeling任务状态为运行

## enhancement
    675 安装包中增加使用用手册文档

#  2017-11-30 version 2.6.0.16
## bug fixed
    677 Windows环境上面，安装modeling插件后，运行数据建模，仍然提示modeling插件未安装
    548 添加对于存储异常的建模任务的停止操作(错误更新修复...)
    546 延长建模任务前段请求超时时间
    641 时间序列使用文档更新
    668  添加测试用例
    634 分析规则部分的使用文档，需要更新
    666 当数据通道为分析通道时，曲线图图标和统计列表显示“分析”字样
    661  对项目增加认证
    655 启停分析通道时，worker日志有异常报错信息
    632 修复Metrics信息查询时间与曲线图横坐标显示不一致的问题
    594 修复使用文档，添加FAQ说明
## enhancement
    675 安装包中增加使用用手册文档
    673 修改cli使用手册



#  2017-11-30 version 2.6.0.15 
## bug fixed

    659 分析规则添加指定字段时，选定关联出来的字段，页面报错
    662 修复float转double的异常
    626 数据源为ftp，文件路径带“-”的情况，运行数据通道不能读取到数据
    658 数据存储为ES5时，运行数据通道失败，worker假死
    657 添加Modeling hdfs 数据源jar包依赖
    667 新建分析类型为“日志归并”的分析规则，成功，但是页面报错
##feature
    661  对项目增加认证

##enhancement 
    282 对Metrics部分进行更新：添加特殊情况说明 
    30 更新使用手册的数据建模部分
#  2017-11-28 version 2.6.0.14 hot fixed
##bug fixed 
    655 解析规则中嵌套字段,重命名失效
    652  修复删除分析规则,提示正在被数据通道使用.实际上二者之间没有任何关系.[勿更改,之前是ok的]
    579 登录页面，填写用户名或密码后又删除，两个输入框间距发生变化
    646 ES数据源添加端口提示
    639 修改分析通道模板，更新相关脚本
    552 修复删除被数据建模绑定的数据源/分析规则/数据存储未做校验的问题.
    648 新建数据通道后无法删除
    594 添加解码器相关说明

#  2017-11-27 version 2.6.0.13 hot fixed
##bug fixed
 643 一键安装脚本增加 netstat 命令校验
 修改时间序列结果的格式
 修改时间序列ARIMA预测不成功
 修改时间序列预测结果时间显示不正确的问题
 设置所给数据量必须大于一个周期的数据
 修改预测结果时间差一个粒度的bug
#  2017-11-27 version 2.6.0.12
 ## bug fixed
    556 校验上传数据建模时的字段.
    643 一键安装脚本增加netstat命令校验
    628 更新使用文档
    282 添加Metrics说明
    644 消除grok 解析中对'_字段名' 的hack 特殊处理
    637 优化数据抽取算法
    530 删除被分析通道绑定的数据通道，未进行校验，直接删除成功
    639 修改分析通道模板，更新相关脚本
    625 运行数据源为HDFS的的数据通道失败， 报hdfs插件未安装，但实际上hdfs插件已安装
    630 字段再解析不能对含有"."符号的属性名称再解析
         标准化漏改
    解决flink异常导致worker宕掉的问题
   631 分析规则中，选择“日志字段时间”，当使用不解析的解析规则时，无法选择“时间字段”
   638 dev分支中只支持linux和window系统安装包编译，测试环境中需要支持aix和hpux的安装包编译
   634 分析规则部分的使用文档，需要更新
   467 sftp\ftp 正则路径不能读取数据问题
   633 分析规则中“最大延迟时间”的提示信息显示不全
   628 Modeling使用的ES数据源未对时间字段进行解析，导致FlinkJob执行时发生类型转换的错误
        Modeling ES5 读取进行修改：增加时间字段的转换；
   624 抽取出 构建FlinkJob失败的原因，并展示出来。
   618 登陆后如果auth server出现问题，页面无法被刷新，并且没有提示!
                   修改为 校验不通过时(包括校验服务器不可用),跳转到登录页面
                   登录时,服务不可用,提示服务不可用!
   582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
   627 运行分析通道成功，点击“点击查看flink任务” 失败
   495 ftp、sftp指定文件不能读取的问题
   623 复制分析规则，选择解析规则后，添加字段属性不可用
   622 HDFS作为数据源时，默认的端口8020不能使用，应改为9000
   540 校验成功时隐藏错误提示
   621 Modeling 表单验证添加红色框提示；
   617 Flink测试连接添加表单验证
   603 频繁多次起停数据通道/分析通道/离线建模/知识库操作，会导致偶发性服务器 [0.0.0.0] 在 [5] s内没有响应报错(或是发生异常：...)
            调整页面的超时时间是20s
            调整服务端的超时时间是15s
   589 运行ES5作为数据源的数据通道失败
   453 数据存储为es2(es5)，数据通道运行中，重启es，数据通道不能自动恢复正常，一直处于写数据异常状态
   613 存储为 ES5时，接收数据会产生文档数为0的 错误索引
   616 运行一个以ES5为数据存储的数据通道，ES5集群状态从不可用到可用，导致入库ES5的数据解析失败
   576 多个数据通道/建模，数据存储为相同索引和索引类型的ES5，启停部分数据通道/建模会影响其他的数据通道/建模存储失败


## enhancement
   635 修改auth默认启用状态为off
   610 修改analysis相关组件的依赖包配置（pom文件），减小编译包大小
## feature
   393  LogAggs 算法
   602   cli中增加日志收集脚本
   


#  2017-11-17 version 2.6.0.11 
## bug fixed
    
    612  后台连接失败问题，导致数据通道运行失败 减去hbse对netty包的依赖,避免冲突
    582  一键安装配置setting.conf文件未提供portal认证时的配置及说明
    588 运行分析通道失败，页面详细报错信息丢失
    607 当“采集器已关闭,或者不存在”时，运行数据通道，提示信息不合理
    605  网络不好，导致“采集器已关闭，或者不存在“
    536 未对flink状态进行校验导致分析通道运行失败，前台未有任何报错提示信息
    568 细化错误信息提示；  完善异常捕获。
    484 去除空行结果
    530 删除被分析通道绑定的分析规则/数据通道，未进行校验，直接删除成功
    609 修复Modeling插件检验导致Worker异常停止
    306 分析规则中: (1)“指定字段”的类型为空 可以保存 (2)"解析规则“为空可以保存
    569 删除被分析规则绑定的解析规则时，未进行校验，直接删除成功
    601 去掉跳转连接；
    600 去掉bug标示。
    475 在无jre和jdk的Linux系统中一键自动安装sage-bigdata-etl ，当setting.env可修改项端口修改为已被占用的端口，安装过程中无报错或者提示
    531 更改默认端口避免与 OMDB，Portal 及 CCI 冲突
    286 gulp 编译问题; `分隔符` 解析规则 UI调整
    595 文档《CLI-Collector使用手册-v11》中知识库对应的解析规则，建议使用文档中进行详细说明
## enhancement
    529 发行版中应该携带版本信息
    610 修改analysis相关组件的依赖包配置（pom文件），减小编译包大小
    565 修改 analysed_time 为a@analyze_time，添加 字段 a@cluster，设置 两个字段为可选添加；
## feature
    602 cli中增加日志收集脚本
## DOC
   606  运行Mysql作为数据存储的数据通道，存储的结果错误




# 2017-11-17 version 2.6.0.10 hotfix
## bug fixed 
    526 数据源hdfs，文件类型为excel有表头，存储数据结果默认之前数据源页面填写过的表头信息
    582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
    595 文档《CLI-Collector使用手册-v11》中知识库对应的解析规则，建议使用文档中进行详细说明
## enhancement
    598 flink streaming sql分析数据通道页面升级
 

# 2017-11-15 version 2.6.0.9 hotfix
## bug fixed
  567 删除Modeling下载配置中的JobId
  591 修复Modeling 中状态检查 bug，修改 Modeling 任务启停逻辑
  596 统一数据库所有表中，创建时间字段为：CREATE_TIME,修改时间字段为：LAST_TIME, 部分表增加IS_SAMPLE字段
  440  数据源类型为本地文件或目录，文件路径为本地目录，运行通道失败
  569 删除被分析规则绑定的解析规则时，未进行校验，直接删除成功
  562 setting.env中配置了mysql的安装，一键安装成功后，运行数据存储为mysql的数据通道失败，提示jdbc插件未安装
  543 上传知识库模板时，采集器为空，但是保存成功
  534 运行分析通道，分析结果中select解析通道中的字段c@receive_time值错误
  508 建议分析规则模板的SQL语句中不要使用"*"
  571 数据建模修复数据源不存在，前端无错误：添加运行时错误捕获并显示与前端
  563 fixed 解析规则数据过滤选择知识库补充，下拉框选项出现未运行的知识库
## feature
 590  pca算法实现
 383 分析规则需要配置watermark
 435 知识库，OMDB集成--添加知识库重新加载后，需要使数据通道使用的知识库重新缓存数据的功能逻辑
## enhancement
 544 建议区分模板和非模板
 597 修改所有列表页面排序为：按创建时间倒序排序

# 2017-11-14 version 2.6.0.8 hotfix
## bug fixed
    356 分析规则中指定字段为解析规则中没有的字段，运行数据通道，未有任何提示信息
    508 建议分析规则模板的SQL语句中不要使用"*"
    582 一键安装配置setting.conf文件未提供portal认证时的配置及说明
    586 复杂解析规则等编辑内容导致保存操作403错误
    570 建模添加数据源、分析插件、数据存储校验；
    584 修改 FlinkAPI 返回值类型错误；
    585 运行数据源为csv的数据通道失败
## feature
    393 LogAggs 算法
# 2017-11-14 version 2.6.0.7 hotfix
## bug fixed
  581 一键安装时，配置文件setting.env添加安装的插件ftp，sftp，hdfs，excel，导致安装失败
  583 修复Flink提交缺少analyzer jar 包的问题
  577 添加测试连接功能；
  551 拆分列表
  517 复制的分析规则修改添加字段时，无法自动关联到解析规则中的字段名
  135 "解析规则"缺失，但预览时未报任何错误
  530 删除被分析通道绑定的分析规则/数据通道，未进行校验，直接删除成功
## enhancement
  565 运行数据建模得到的结果中analysed_time字段不可选，建议改为可选字段



# 2017-11-13 version 2.6.0.6 
## bug fixed 
    去掉sage-bigdata-etl-streaming模块的akka-http包
    304 采集器后台进程存在，页面采集器状态已关闭或者不存在，采集器不可用
          1. 修改worker连接Master的策略 client ,每次重建;
          2. 修改 页面停止worker的逻辑,不使用Await,并检查 daemon 返回的状态;
    281 数据通道（本地excel文件到kafka）运行一段时间后，往本地目录下新增多个文件，读取到部分文件的数据条数为0
    529 修复页面图标显示异常;
        修改CLI使用手册，添加Modeling使用说明
    562 setting.env中配置了mysql的安装，一键安装成功后，运行数据存储为mysql的数据通道失败，提示jdbc插件未安装
    560 自动安装sage-bigdata-etl，在初始化数据库时有删表失败error提示，建议文档中添加说明
    558 ES2/ES5数据存储页面集群名称缺少必填项标志
    467 数据源为ftp，sftp时，文件路径为正则匹配，不能匹配读取到对应文件
    540 对时间段查询校验，添加错误提示
    518 数据源为kafka，解析过滤规则为知识库补充，存储为es5。运行数据通道，数据无法解析并存储。多次起停操作，提示失败，采集器被关闭
         删除多余的打印日志
    519 数据源为kafka，给已完成解析的kafka中添加数据，再次启动数据通道后数据读取数据错误
        修复分析模块重构后前后端不一致的问题
    476 已经运行成功的知识库，再次点击运行，状态不会变
    378 选择数据源为sftp，"文件路径"指定到目录导致运行数据通道失败
    520 CLI-Collector使用手册验证
    529 发行版中应该携带版本信息 
    484 修复建模遇到空行自动补填问题
    493 数据源为本地文件或类型，文件类型为csv，填写表头信息，运行数据通道得到的数据默认源文件第一行数据为表头信息
    440 数据源类型为本地文件或目录，文件路径为本地目录，运行通道失败。
    298 Kafka读取超时，导致只有部分数据存入ES2，但UI上无任何错误提示
    370 日志缺少kafka写入，和读取的详细信息,例如写入多少条数据，读取了多少条数据
    561 增加文档说明默认开箱即用的模板 
## feature
    393 LogAggs 算法
    223 数据分析数据预览接口
    539 worker再启动worker,worker连接到master用时较长
           修改相关的配置参数
           调整前端获取采集器状态的逻辑
    524 增加时间序列的预测模型实现
                 重构分析模块结构
    分析规则需要配置watermark
    修改“采集进度”：均值 -> 1分钟均值
    483 启动任务前检查Flink可用slots

## enhancement
    529 发行版中应该携带版本信息
    574 丰富setting.env配置文件中，默认安装组件
    573 修改一键安装脚本，解决组件名称中带有“-”不能安装问题
    494 数据建模演示停止、异常原因
        修改Master.conf模板配置，标识过期参数
 
    494 通过 Flink WebUrl 获取Flink RPC地址；在页面中只填写Flink WebUrl
    516 增加开箱模板
    496 Metrics信息查询抽取；
            Writer Metrics显示名称
    392 系统标准化,初始化,预制规则;
    494 添加sage-bigdata-etl-flink-common模块；
## DOC
    205 基于数据通道版本的文档更新 -- 用户使用手册
 



# 2017-10-31 version 2.6.0.5 hotfix
bug fixed  
    515 ES 作为数据存储，数据处理方式存在问题，使部分数据丢失，未处理的数据记录在了error中
                    当是连接问题时,直接retry 否则写error index
    512 修改分析规则后，保存失败
DOC
     李毅提交ElasticSearch5安装部署-20171030-v1.docx文档。
   sage-bigdata-etl日志标准文档
TEST
    增加时间序列模型ARIMAX及单元测试

# 2017-10-30 version 2.6.0.4 hotfix
    bug fixed
    507 当没有安装插件时,采集器worker起不来
    408   源类型为ftp/sftp时，目前只支持“文本”和“windows日志文件“， 建议增加目前本地文件支持的其他文件类型
                    UI添加了对应的数据源,去掉winevt 非本地(Windows)暂时不支持evt
                    EXcel后端切换直接从wrapper读取,避免只是本地文件(需要测试)
    166 后台反馈的消息没有经过处理就在前台直接展示，去掉显示的ID
    在无jre和jdk的Linux系统中一键自动安装sage-bigdata-etl ，当重复安装时，会导致原有的master进程被杀
DOC
    ElasticSearch5安装部署-20171029-v1.docx文档。
     
TEST
    增加时间序列模型的测试模块---例如DickeyFuller-test
    ARIMA 测试通过


# 2017-10-27 version 2.6.0.3
##bug fixed  
    修复分析完的时间为正常时间（yyyy-MM-dd HH:mm:ss格式）  
    #427 新建数据存储为es5时，页面输入框提示不正确  
    #481 一键自动安装sage-bigdata-etl中，配置文件setting.env支持插件提示不正确  
    #502 知识库管理列表中，初始任务状态是“未知”，修改初始状态为“未执行”  
    #503 采集器信息不存在时，数据通道列表页面打不开  
    #493 数据源为本地文件或类型，文件类型为csv，填写表头信息，运行数据通道得到的数据默认源文件第一行数据为表头信息   
    #458 源类型为HDFS时， 建议增加目前本地文件支持的其他文件类型‘excel‘，‘csv’  
    #306 分析规则中: (1)“指定字段”的类型为空 可以保存 (2)"解析规则“为空可以保存  
    #491 数据源为本地文件或目录，路径为正则匹配，添加新的数据或新的文件不被读取  
        1)添加CSV Test case  
        2)修改页面相关的问题  
    #352 分析规则里的字段类型和解析规则里的字段类型不匹配会导致分析规则数据通道运行失败,并且前台无报错  
    #343 含有分析规则的数据通道，当flink异常时，数据通道停止失败  
    #484 #486 modeling 以 HDFS 为数据源时，会跳过空行、解析失败继续读取  
    #490 数据源为本地文件或目录，文件类型为excel或csv，选择无表头，表头信息输入框变成了非必填项  
    #485 修改 ES Query Json 选项为非必填选项  
    #230  复制数据通道时，默认会把底下的4个选项打开，而在原数据通道中这四项是关闭的   
    #478 解析规则中使用知识库补充时，“数据字段”和“知识库字段” 不匹配，导致运行数据通道后，数据存储无数据  
    #153  "解析规则"缺失，但预览时未报任何错误  
    #428  数据源处的表单信息填写错误，提示信息重复  
    #487  新建分析通道，选定“数据通道”并保存成功，再打开时“数据通道”为空  
    #446 添加Modeling状态控制  
    #489 文件单元测试  
    #488 新建数据源为本地文件或目录，有表头的csv文件类型，保存成功后再次打开，“是否有表头”变为无  
    #368 分析规则中，SQL缺少校验导致运行分析通道失败，前后台无明显报错提示信息  
    #166 后台反馈的消息没有经过处理就在前台直接展示，去掉显示的ID  
    #454 HDFS作为数据源，运行数据通道后，部分数据读取不到  
    #448 数据源为本地文件或目录，文件类型为excel,读取数据错误，excel的日期格式底层存储是数字类型，需要单独处理，已解决，另外，其他数字类型api里返回的是double，整数类型的数据返回的都是#.0的格式，不需要处理  
    #473 Worker未安装mysql的plugin时运行知识库，报出错误但是出错信息不明确  
    #433 新建数据源windows日志文件保存后，数据源页面不显示任何数据 
    
##feature    
    #383 分析规则需要配置watermark  
    #435知识库，OMDB集成  
        1)添加启动数据通道时对解析规则依赖的知识库状态的校验  
        2)CLI文档更新  
    添加sage-bigdata-etl-ml模块  
       
##enhancement  
    #392 系统标准化,初始化,预制规则;  
    #461 知识库需要状态显示  
    
##unitTest  
    添加CSV Test case  
    添加ARIMA 测试用例  
    
##doc  
    李毅在2017-10-27 12:49提交CLI-Web安装使用手册-20171026-v1.docx文档  
    李毅在2017-10-26 17:46提交<<ElasticSearch5安装部署-20171026-v1.docx>>  



# 2017-10-20 version 2.6.0.2
bug fixed 
    384 重构补充信息的处理逻辑,
                     1.解析
                     2.添加
                     3.过滤
                     4.对于不需要的就移除
    354 新建分析规则，分析规则未填写任何配置信息，点击保存，保存成功
    410 数据存储为本地文件，文件路径使用描述信息有问题
    426 新建数据存储为SYSLOG,发送地址和发送端口填不符合规则的数据时可以保存成功
    451 创建数据存储为hdfs，输出格式为默认的json格式，保存后再次打开该数据存储，输出格式为空
    451 创建数据存储为hdfs，输出格式为默认的json格式，保存后再次打开该数据存储，输出格式为空
    460 解析规则添加“数据过滤”，规则为数据重定向，匹配相关的和包含时，选择字段再解析，无输入框
    459 数据源处的解码器选择分隔符，分隔符未进行必填项校验
    448 数据源为本地文件或目录，文件类型为excel,读取数据错误，excel的日期格式底层存储是数字类型，需要单独处理，已解决，
        另外，其他数字类型api里返回的是double，整数类型的数据返回的都是#.0的格式，不需要处理
    457 数据通道点击启动按钮后，状态（PENDING）汉化为“未知”，修改成“正在启动”
    440 数据源类型为本地文件或目录，文件路径为目录的情况，判断文件权限bug。
    445 数据源为csv或excel时，是否有表头的信息没有持久化的问题
    439 数据存储为网络，数据输出格式为键值对时，分隔符和键值分隔符没有必填标志
    186 知识库设计实现 修改知识库的删除，以及创建知识库时重名问题的修改。
    fix flink streaming module
    414 两个数据通道都是用同一个es2作为数据存储，同时运行后再进行启停操作后会导致写数据异常
    429 数据源为FTP，SFTP，HDFS，解码器选择多行，出现了两个正则框

feature 
   435 知识库，OMDB集成
       汉化运行状态，更改阈值模板
       修改解析规则加载的知识库列表接口，只加载已经完成的知识库
       添加数据源校验，修改知识库running状态的更改时机，修改二次运行知识库表覆盖的逻辑
   419 kill掉daemon和worker进程，数据通道状态没有改变
   437 安装程序时，将数据标准化模板导入到数据库中
   421 在无jre和jdk的AIX系统中一键安装sage-bigdata-etl
   422 在无jre和jdk的HPUX系统中一键安装sage-bigdata-etl
   423 在无jre和jdk的LINUX系统中一键安装sage-bigdata-etl
   
unitTest
    提交sage-bigdata-etl-hdfs单元测试用例。
    提交sage-bigdata-etl-sftp项目测试模块代码

enhancement  
    503 集成公司portal权限系统,
        当关闭了后端代码的权限验证功能，仍然能够使用任意用户名密码登录UI。
    431 完成主要的功能，还需要和前端协调一个获得资源列表功能的API
    RichMap 修改 支持向列表中添加数据 完善相关测试用例
    452 数据通道、数据源、解析规则、分析规则、知识库、数据存储中，数据模板记录隐藏修改和删除操作



# 2017-10-17 version 2.6.0.1
##Feature
    437 安装程序时，将数据标准化模板导入到数据库中
    435 知识库，OMDB集成
    421 无jre和jdk的AIX系统中一键安装sage-bigdata-etl
    422 无jre和jdk的HPUX系统中一键安装sage-bigdata-etl
    423 无jre和jdk的LINUX系统中一键安装sage-bigdata-etl
    410 数据存储为本地文件，文件路径使用通配符，生成的存储文件路径错误

##bug fixed 
   186 知识库设计实现 修改知识库加载,和使用
   186 知识库设计实现 没有使用过滤规则
   368 分析规则中，SQL缺少校验导致运行分析通道失败，前后台无明显报错提示信息。
   386 akka.remote发送信息大小限制导致分析通道运行失败
   425 数据存储为SYSLOG，两个数据通道存储到不同syslog服务器时，其中一个通道数据无法存储
     1.添加网络相关的测试用例
     2.移除掉Syslog 输出,增加syslog输出格式
   424 在无jre和jdk的WINDOWS系统中手动安装sage-bigdata-etl
   399 当Kafka作为数据存储不存在时，运行数据通道无任何报错（修改check kafka集群验证方式）
   328 解决HDFS作为数据源时，运行数据通道，读到的数据为0
   351 运行数据通道，flink job提交失败，前台添加报错信息
   373 数据源（本地文件或目录）缺少校验导致运行数据通道失败，无报错，日志中无提示信息
   243  当数据源来源是已经格式化好的数据时，`添加原始数据`没有效果
   304 解析规则，解析类型为xml时，预览结果不正确
   299 数据通道（kafka到es-2.x）运行过程中es出现网络故障，写数据异常，es网络恢复后，数据通道无法自动恢复
   398 数据通道运行过程中停止采集器，数据通道停止失败
   409 控制台启动停止HP-UNIX & AIX系统的work输出不正常
   396 HP-UNIX环境启动worker脚本后work.conf和logback-worker.xml文件被置空

##enhancement 
       添加数据通道类型,数据源类型,分析规则类型,解析规则类型
   392 系统标准化,初始化,预制规则;
       enhancement add datasource type for 2.6.x
      NetDataWriter use syslog format
   403 资产类型相关全部去掉
   404 [UI] 资产类型相关全部去掉
   261 writer插件验证是否安装
   261 对写入插件进行是否安装的验证，多写入的情况下，只要有一个没有安装，通道不允许执行，前端给出未安装的错误提示
   
   166 后台反馈的消息没有经过处理就在前台直接展示
   数据建模ES5数据源添加Type和query条件支持
##Unit Test
   420 KAFKA插件单元测试（UT）--主要是基于test case修复的bug
   406 提炼公共接口,重构分析相关的model 与streaming相关的代码
       完善相关的测试用例
      添加sage-bigdata-etl-modeling Test Case
   406 重构代码,能够不需要skipTests

##DOC  
   CLI文档更新
    
# 2017-09-19 version 2.5.3.10
##bug fixed

     369 运行ES2作为数据存储的数据通道失败
     329 当监控本地文件目录时,会有内存泄漏

    366 数据过滤规则中“default”处理使用“删除” 后，导致使用正则，包含等过滤规则不生效
    344 解析规则为不解析，预览时显示“raw_raw“。问题2: 解析规则为分隔符等时预览和解析后的结果里没有“raw”字段
    179 2.5.x分支暂时注释掉解析规则与数据储存的字段列表的验证功能
    323 删除一个被数据通道绑定的解析规则时成功，导致绑定这个解析规则的数据通道里的解析规则为空(主要是修改删除失败时的提示信息)
    333 配置解析规则数据过滤为数据重定向，同时配置了case和default,运行数据通道，解析得到的结果有误
    362 默认值改成false,等待时间改成0


    bug fixed:[Bug]分析规则中: (1)“指定字段”的类型为空 可以保存 (2)"解析规则“为空可以保存
##doc
     358 CLI-Collector自动安装脚本和文档问题
         修改auth不安装时master启动问题，替换app.min.js中的auth，状态

# 2017-09-11 version 2.5.3.9
## bug fixed 
    329 当监控本地文件目录时,会有内存泄漏,切内存过高
    312 sage-bigdata-etl-manual.doc中，建议对分析规则章节内容作进一步解释说明
    315 删除含有分析规则的数据通道失败

        修改es2和es5冲突校验
        修改sqlserver和sqlserver_jtds冲突校验
        去掉daemon安装配置属性，daemon是伴随worker一起安装的
    349  在解析通道和分析通道采集器不一致的情况下，分析通道运行失败
    328  HDFS作为数据源时，运行数据通道，读到的数据为0
## doc  
    328  文本文件由于无法自动识别编码导致解析失败

# 2017-09-11 version 2.5.3.8
## bug fixed 
    329 当监控本地文件目录时,会有内存泄漏,切内存过高
           1. 使用更少的线程数
           2. 控制只读取最新的
    337 数据源选择“网络”->"NETFLOW"时， 页面应该不显示tcp，因为netflow不支持tcp
    319 选择SFTP/FTP作为数据源，“解码器”只能为空，导致数据通道运行失败
    
        同时修改数据源中，解码器在不同类型数据源中显示问题，修改es2、es5，保存后点击修改不现实问题
## enhancement
    修改preinstall.sh脚本，完善一键安装
    更新setting.env文件信息内容
# 2017-09-11 version 2.5.3.7
## bug fixed 

    329 当监控本地文件目录时,会有内存泄漏,切内存过高
    321 以“本地文件或目录”来作为数据源时，选择“解码器“为”无“，保存失败
    338 创建含有分析规则的数据通道，"flink集群地址"输入框中的说明不合理
    320 以Mysql作为数据存储，数据通道运行后出错(修改mysql没有number类型bug)

# 2017-09-11 version 2.5.3.6
## bug fixed 

 - 329 当监控本地文件目录时,会有内存泄漏
   >1. 增加自定义Mailbox  当队列堆积文件数超过10000 时,移除最早的数据
   >2. 修改 内置的forward cache 大小为所配置的其他writer的最大值
 -  332 磁盘空间不足时，worker启动失败，清理后，worker启动仍然失败
 -  300 前台页面点击停止采集器，采集器停止失败
 -  320 以Mysql作为数据存储，数据通道运行后出错
 -  316 新建源类型为es的数据源，保存失败
 - 327 HDFS作为数据存储时，存储到hdfs的文件，第一行为空
 - 323 删除一个被数据通道绑定的解析规则时成功，导致绑定这个解析规则的数据通道里的解析规则为空
 - 323 删除一个被数据通道绑定的解析规则时成功，导致绑定这个解析规则的数据通道里的解析规则为空


##enhancement 
  - 336 所有的`数据输出`都应该可以配置数据缓存
  - 166 后台反馈的消息没有经过处理就在前台直接展示 接口已调整，待测试完善

# 2017-09-07 version 2.5.3.5
## bug fixed 
    329 当监控本地文件目录时,会有内存泄漏
    324 创建一个不解析的解析规则点预览
    317 运行数据源（本地csv至本地文件），解析得到的数据多出length字段
    322 删除一个被数据通道绑定的数据存储/数据源时成功，导致绑定这个数据存储的数据通道里的数据存储/数据源为空
    315 删除含有分析规则的数据通道失败
    304 解析规则，解析类型为xml时，预览结果不正确
    318 netflow 使用tcp协议启动失败
    197 运行数据通道后，前端页面无任何信息提示，无响应，只有日志中有提示信息。请在前台页面补充相关提示信息。
    313 在数据源中以多行来读取文本文件失败
    299 数据通道（kafka到es-2.x）运行过程中es出现网络故障，写数据异常，es网络恢复后，数据通道无法自动恢复
    310 解析规则的数据过滤使用包含不起作用
    29 实时SQL分析：解决解析出的时间字段flink sql不能使用的问题

## enhancement   
    修改netflow解析时间DateTime为java.util.Date
    29 实时SQL分析：增加时间可选字段类型->long
##test case    
    304 xml解析规则testcase


#2017-09-01 version 2.5.3.4
 ##bug fixed
   195 数据存储使用HDFS时，运行数据源会导致worker重启
    数据输出是`条件输出`时,无法选择其他`数据输出`
    修改js错误：双引号改为单引号
    190 sage-bigdata-etl的UI页面里很多的下拉菜单没有显示默认值，但实际上执行时是有默认值的
    239 新建数据源，选定文件类型为excel时，excel表头信息栏建议改为非必选项
    293 创建好的数据源的资产类型为空
    292 启动含分析规则的数据通道会将work停掉
 ##enhancement
    分组数据通道页面
    es2  es5 可以同时使用
   186 知识库：数据库为数据源加载到知识库调整
   
#[CHANGE-LOG 201701 到 201708](CHANGE-LOG-2016_201708.md)
